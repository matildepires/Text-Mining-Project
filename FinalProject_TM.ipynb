{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "# Text Mining Project<a id='title'></a></b><br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "1 - [<font color='#000000'> Preprocessing</font>](#pro) <br>\n",
    "2 - [<font color='#000000'> Simpler metrics</font>](#simple)<br>\n",
    "3 - [<font color='#000000'> More complex metrics</font>](#da)<br> \n",
    "4 - [<font color='#000000'> Training and Development Split</font>](#trdv)<br> \n",
    "5 - [<font color='#000000'> Models with bag of words</font>](#bow)<br> \n",
    "6 - [<font color='#000000'> Models with word embeddings</font>](#embed)<br> \n",
    "7 - [<font color='#000000'> Combining metrics</font>](#comb)<br> \n",
    "8 - [<font color='#000000'> Correlations (Pearson and Kendall)</font>](#corr)<br> \n",
    "9 - [<font color='#000000'> Applying it to test set</font>](#test)<br> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_similarity\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fi, cs_en, en_zh, ru_en, zh_en, de_en = pd.read_csv(\"corpus/en-fi/scores.csv\"), pd.read_csv(\"corpus/cs-en/scores.csv\"), pd.read_csv(\"corpus/en-zh/scores.csv\"), pd.read_csv(\"corpus/ru-en/scores.csv\"), pd.read_csv(\"corpus/zh-en/scores.csv\"), pd.read_csv(\"corpus/de-en/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 1. Preprocessing</font> <a class=\"anchor\" id=\"pro\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For translations for English and Finnish (cs-en, ru-en, zh-en, de-en, en-fi)\n",
    "\n",
    "def preprocessing(dataframe, column, toEnglish=True, stemming=False, stopwrd=False):\n",
    "# The default is not removing stopwords or stemming, just lowercasing and removing punctuation\n",
    " \n",
    "    processed_corpus = []\n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = list(dataframe[column])[i]\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Convert to list from string\n",
    "        text = text.split()\n",
    "                \n",
    "        # Remove punctuation\n",
    "        text = [word.translate(str.maketrans('', '', string.punctuation)) for word in text]\n",
    "        \n",
    "        # Remove stopwords\n",
    "        if stopwrd:\n",
    "            # Default is English\n",
    "            if toEnglish:\n",
    "                stop_en = stopwords.words('english') \n",
    "                text = [word for word in text if word not in stop_en]\n",
    "            else:\n",
    "                stop_fi = stopwords.words('finnish') \n",
    "                text = [word for word in text if word not in stop_fi]\n",
    "\n",
    "        # Stemming\n",
    "        if stemming:\n",
    "            # Default is English            \n",
    "            if toEnglish:\n",
    "                stem_en = SnowballStemmer('english')\n",
    "                text = [stem_en.stem(word) for word in text]\n",
    "            else:\n",
    "                stem_fi = SnowballStemmer('finnish')\n",
    "                text = [stem_fi.stem(word) for word in text]\n",
    "        \n",
    "        text = \" \".join(text)        \n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For translations for Chinese (en-zh)\n",
    "\n",
    "# !pip install jieba\n",
    "import jieba\n",
    "\n",
    "def preprocessing_chinese(dataframe, column):\n",
    "    \n",
    "    processed_corpus = []\n",
    "    no_punc=dataframe[column].str.replace(r\"[%s]+\"%punc, \"\").astype(str)\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(no_punc))):\n",
    "        text = no_punc[i]\n",
    "        \n",
    "        text=[word for word in jieba.cut(text)]\n",
    "        \n",
    "        text = \" \".join(text)   \n",
    "        \n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c573a10ca484ce1ae511424b9e4dbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfa0840ceec461e85e2337f9cd1eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d86fd5c393f4a5da8371c81d659f5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ff5d30440e4c2aaf5e01abc068c76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953a7da2c30f4ed5a4419a79b0440fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2018135d124f9e9ada4d0e9e5410c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a643037b8441938aa309e9761f66ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c625486f349241308d8ad5ae576be146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5a56b0b31a420785737f84ab30a5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3980a6d426a64cb6821c5c43624a5b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c80fac6b7543639c5a112660f6b4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04babc6e866b4870b8d179c4b3b7c1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0147875f02314def8526f1b2e7dfbb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0ac63ef272427d8fd4af069f229cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4f4fb62bb442fab93009e9d9cda207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe6a3d8248c43bfae883891b1686f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cade8cbf73407caa89ea6b145bbb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3504dbd62c405eb3d304ef993dd63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387d92331a1439da501c4e182b1b445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a599b556e341229f5e3be6afc254e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2359e876cf48dfbc29f02ef058545e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644b7f38c9a4e57973899e365c80c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the preprocessing to the corpora with English translations\n",
    "\n",
    "for i in [cs_en, ru_en, zh_en, de_en]:\n",
    "    i['clean_translation_1'] = preprocessing(i, 'translation') # no punctuation and all in lower case\n",
    "    i['clean_reference_1']= preprocessing(i, 'reference')\n",
    "    \n",
    "    i['clean_translation_2'] = preprocessing(i, 'translation', stemming=True, stopwrd=False) # without punctuation, stopwords and with stemming\n",
    "    i['clean_reference_2']= preprocessing(i, 'reference', stemming=True, stopwrd=False)\n",
    "    \n",
    "# Applying the preprocessing to the corpus with Finnish translations\n",
    "\n",
    "en_fi['clean_translation_1'] = preprocessing(en_fi, 'translation')\n",
    "en_fi['clean_reference_1']= preprocessing(en_fi, 'reference')\n",
    "\n",
    "en_fi['clean_translation_2'] = preprocessing(en_fi, 'translation', stemming=True, stopwrd=False, toEnglish=False)\n",
    "en_fi['clean_reference_2']= preprocessing(en_fi, 'reference', stemming=True, stopwrd=False, toEnglish=False)\n",
    "\n",
    "# Applying the preprocessing to the corpus with Chinese translations\n",
    "\n",
    "en_zh['clean_reference']= preprocessing(en_zh, 'reference')\n",
    "en_zh['clean_translation']= preprocessing(en_zh, 'translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that have an empty reference\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i = i[~(i.clean_reference_1 == '')]\n",
    "    i = i[~(i.clean_reference_2 == '')]\n",
    "    i = i[~(i.clean_translation_2 == '')]\n",
    "    i = i[~(i.clean_translation_1 == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_en.isna().sum() # run for all languages to see if any reference/translation is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_en[zh_en.clean_reference_1.isnull()] # The reference is empty -- > error\n",
    "zh_en = zh_en[~zh_en.clean_reference_1.isnull()] #--> removing those records\n",
    "\n",
    "zh_en.iloc[24028:24029] #--> this line has an issue because it does not have a reference --> error (caught when running TER)\n",
    "zh_en = zh_en[~((zh_en.clean_reference_1=='   ')|(zh_en.clean_reference_1=='     '))] #--> removing this record and all similar\n",
    "\n",
    "ru_en[ru_en.clean_reference_1.isnull()] # The reference is empty -- > error\n",
    "ru_en = ru_en[~ru_en.clean_reference_1.isnull()] #--> removing those records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the preprocessed corpora into new csv's to facilitate their usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_fi.to_csv('en_fi_clean.csv')\n",
    "# cs_en.to_csv('cs_en_clean.csv')\n",
    "# ru_en.to_csv('ru_en_clean.csv')\n",
    "# zh_en.to_csv('zh_en_clean.csv')\n",
    "# en_zh.to_csv('en_zh_clean.csv')\n",
    "# de_en.to_csv('de_en_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "      <th>chrf</th>\n",
       "      <th>clean_translation_1</th>\n",
       "      <th>clean_reference_1</th>\n",
       "      <th>clean_translation_2</th>\n",
       "      <th>clean_reference_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333695</td>\n",
       "      <td>their slow speed was measured by researchers o...</td>\n",
       "      <td>her timeless pace measures them when they equi...</td>\n",
       "      <td>slow speed measur research svalbard fit six an...</td>\n",
       "      <td>timeless pace measur equip six anim broadcast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.740196</td>\n",
       "      <td>he said the spaces provided calm meeting point...</td>\n",
       "      <td>he said the areas offer quiet meeting points b...</td>\n",
       "      <td>said space provid calm meet point refuge volunt</td>\n",
       "      <td>said area offer quiet meet point refuge volunt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "\n",
       "   annotators      chrf                                clean_translation_1  \\\n",
       "0           1  0.333695  their slow speed was measured by researchers o...   \n",
       "1           2  0.740196  he said the spaces provided calm meeting point...   \n",
       "\n",
       "                                   clean_reference_1  \\\n",
       "0  her timeless pace measures them when they equi...   \n",
       "1  he said the areas offer quiet meeting points b...   \n",
       "\n",
       "                                 clean_translation_2  \\\n",
       "0  slow speed measur research svalbard fit six an...   \n",
       "1    said space provid calm meet point refuge volunt   \n",
       "\n",
       "                                   clean_reference_2  \n",
       "0  timeless pace measur equip six anim broadcast ...  \n",
       "1     said area offer quiet meet point refuge volunt  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 2. Simpler Metrics</font> <a class=\"anchor\" id=\"simple\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "### 2.1. Distance Metrics to Measure Sentence Similarity\n",
    "**Euclidean Distance, Manhattan Distance, Cosine Similarity & Jaccard Similarity**\n",
    "\n",
    "https://github.com/makcedward/nlp/blob/master/sample/nlp-3_basic_distance_measurement_in_text_mining.ipynb\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#pairwise-metrics\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Jaccard Similarity\n",
    "\n",
    "def calculate_position(values):\n",
    "    x = []\n",
    "    for pos, matrix in enumerate(values):\n",
    "        if matrix > 0:\n",
    "            x.append(pos)\n",
    "    return x\n",
    "\n",
    "def padding(sentence1, sentence2):\n",
    "    x1 = sentence1.copy()\n",
    "    x2 = sentence2.copy()\n",
    "    \n",
    "    diff = len(x1) - len(x2)\n",
    "    \n",
    "    if diff > 0:\n",
    "        for i in range(0, diff):\n",
    "            x2.append(-1)\n",
    "    elif diff < 0:\n",
    "        for i in range(0, abs(diff)):\n",
    "            x1.append(-1)\n",
    "    \n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_calculate(data, translation, reference, measurement=euclidean_distances, avg_type='micro'):\n",
    "    translations = data[translation].to_list()\n",
    "    references = data[reference].to_list()\n",
    "    \n",
    "    final_results = []\n",
    "\n",
    "    for i in tqdm(range(len(translations))):\n",
    "        text = translations[i] + ' ' + references[i]\n",
    "\n",
    "        tokens_on_each_sentence = [translations[i].split()] + [references[i].split()]\n",
    "\n",
    "        tokens = text.split()\n",
    "\n",
    "        label_enc = LabelEncoder()\n",
    "        onehot_enc = OneHotEncoder()\n",
    "\n",
    "        encoded_all_tokens = label_enc.fit_transform(list(set(tokens)))\n",
    "        encoded_all_tokens = encoded_all_tokens.reshape(len(encoded_all_tokens), 1)\n",
    "\n",
    "        onehot_enc.fit(encoded_all_tokens)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for a in tokens_on_each_sentence:\n",
    "            encoded_words = label_enc.transform(a)\n",
    "            \n",
    "            encoded_words = onehot_enc.transform(encoded_words.reshape(len(encoded_words), 1))\n",
    "\n",
    "            results.append(np.sum(encoded_words.toarray(), axis=0))\n",
    "\n",
    "        final_results.append(results)\n",
    "\n",
    "    all_dists = []\n",
    "        \n",
    "    if measurement == jaccard_score:\n",
    "        for i in tqdm(range(len(final_results))):\n",
    "            y1, y2 = calculate_position(final_results[i][0]), calculate_position(final_results[i][1])\n",
    "\n",
    "            x1, x2 = padding(y1, y2)\n",
    "\n",
    "            dist = measurement(x1, x2, average=avg_type)\n",
    "\n",
    "            all_dists.append(dist)\n",
    "            \n",
    "    else: # either euclidean_distances, manhattan_distances or cosine_similarity\n",
    "        for i in tqdm(range(len(final_results))):\n",
    "            dist = measurement([final_results[i][0]], [final_results[i][1]])[0][0]\n",
    "\n",
    "            all_dists.append(dist)\n",
    "\n",
    "    return all_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d704e50ba9064860858c662ff4ab8dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eef5932b6148d4aa39293a7dc0c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5ddf5220f14c288e818773fb910452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e0ee41a6074f1a9c6eb4a6f0e01d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f25b5a792814ce4801954b2e93cfe9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57152426aeb4070a45f011f7cdfd1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917815567fa642559fbe9b10f2e457ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba00583cba643b1b1b4ff4ea0658937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7f6de8f5c146f3a899c80833a037b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7067c53aef0144b8be95e3fbffb49dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e04a21dad034046b4214bf5e28589c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dc370397c141c983da5600317cf330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d27389706348dfa269e30a7080572a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5e0be937374ed0bb2026c46b098613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f90f2a61334f858882f561544d887f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764c34752489466b85291d43b1ee7337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8323fa03f57b45219478875462143340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4df06c13f643629ceff898b2b47993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86c2c721cf841109535b7a19724f7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433bc6a210af4db0aaa8cfc9b9abefa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3746c1aadea447b2b03f316620bcfc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f059e8f3bfaa40108b634642ef4ca6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880b5bacf8eb40b3bf67830c5a63144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744cdca5293344e7bd1cc1bb53da84b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the 4 distance metrics to Preprocessing 1 for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['euclidean_dists_1'] = transform_and_calculate(i, 'clean_translation_1', 'clean_reference_1', euclidean_distances)\n",
    "    i['manhattan_dists_1'] = transform_and_calculate(i, 'clean_translation_1', 'clean_reference_1', manhattan_distances)\n",
    "    i['cosine_sim_1'] = transform_and_calculate(i, 'clean_translation_1', 'clean_reference_1', cosine_similarity)\n",
    "    i['jaccard_sim_1'] = transform_and_calculate(i, 'clean_translation_1', 'clean_reference_1', jaccard_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9119bfaab041a39b9cb3b2a504462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995f616f677b43519a51a66125e1436c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d418826fef4ca98b4192987fce85ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f6e7fee4a64237aaa5b203473d639a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d53727f71a4c7b90af4b03c38ea208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827fdeef566c415c9e1b85769ceb2457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5942fb34e645ea80c913b3e884df97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a762e3d5d7452abfa2854b97bef88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d1a99520554da493b40b09de3ffc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91726909a8c490ba454444436f43f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11211feb861546ca940191a0b0080352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a0fc5c3ca7411fb25e5169a4a9d245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c547a59526c54d1288219932d7a2d44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01feba16014448968abe8cce35e1fdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e68c4d55efe473f91c604a73ef4833b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241db1311abc405399cee93841b3cf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4526b5a28f5b4f7a83c29f6d30398728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e014c1f1c844a3ea81a8e8479088137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09bae2c195e45059ae26e647d652564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5176e0992424650949ed28e00286c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11de299a0c8a4beeb657249bf68b6a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e135bca9e4c94aac9a22b598134a5143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569bb6c77bd643cebf238295132248f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d12df2d0d7044d2bc35574efa2a0832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7959506d122a4231a874aebdeb803c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb21e7db50b442c99cae3e80b115a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c070a5ce4c7c40bf8b4557e8576b4bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e531ecf5ab384c6a80ca7647a5944613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de8e02f49c341269430d1c1f9d64695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514645a1b85d40bda4802ab41eb9b74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f12f87731a7464c94bc10064448e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8415c9f4a8a14678a6f596108c648b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d5c8876aa541698cea5cc3e754c5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8776d8a74d42e4b9fbf56ba5819e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11f4329418d42bcbfa0776de7df568e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458e931c3743407eb86fb23fc50bf82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240b2506ce4e49b3b0c2d5e0927c4dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4acc1cb97b6469db939e77a152c4a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0e9b515dd5426fa154c606fa197867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e0fd3f46ce43ed84fe0529a8cf2657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the 4 distance metrics to Preprocessing 2 for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['euclidean_dists_2'] = transform_and_calculate(i, 'clean_translation_2', 'clean_reference_2', euclidean_distances)\n",
    "    i['manhattan_dists_2'] = transform_and_calculate(i, 'clean_translation_2', 'clean_reference_2', manhattan_distances)\n",
    "    i['cosine_sim_2'] = transform_and_calculate(i, 'clean_translation_2', 'clean_reference_2', cosine_similarity)\n",
    "    i['jaccard_sim_2'] = transform_and_calculate(i, 'clean_translation_2', 'clean_reference_2', jaccard_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f168388e24007a10b6fd3eb5c19ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce7e3ac8d6d4b3c80c7fdf5a86a45da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e863a3697974815bf9a7cd1727a2637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0ae20701f64daa9b9f65bbaa7605f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32429d11776c40d39627000f4a479e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ab78b630eb492aae699a17dae84e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f62bf62f8f04727ad54947594ecf52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ad893a73594f5198ee8ef204c4c0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the 4 distance metrics to the Chinese translation (en-zh)\n",
    "\n",
    "en_zh['euclidean_dists'] = transform_and_calculate(en_zh, 'clean_translation', 'clean_reference', euclidean_distances)\n",
    "en_zh['manhattan_dists'] = transform_and_calculate(en_zh, 'clean_translation', 'clean_reference', manhattan_distances)\n",
    "en_zh['cosine_sim'] = transform_and_calculate(en_zh, 'clean_translation', 'clean_reference', cosine_similarity)\n",
    "en_zh['jaccard_sim'] = transform_and_calculate(en_zh, 'clean_translation', 'clean_reference', jaccard_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 2.2. BLEU\n",
    "\n",
    "(Bi-Lingual Evaluation Understudy) score was first proposed in 2002. The most widely used metric for MT evaluation, due to its presumed high correlation with human rankings of MT output.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bleu\n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying BLEU for both Preprocessings for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['bleu_1'] = i.apply(lambda row: sentence_bleu([row['clean_reference_1']],row['clean_translation_1']), axis=1)\n",
    "    i['bleu_2'] = i.apply(lambda row: sentence_bleu([row['clean_reference_2']],row['clean_translation_2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying BLEU for en-zh language pair\n",
    "\n",
    "en_zh['bleu'] = en_zh.apply(lambda row: sentence_bleu([row['clean_reference']],row['clean_translation']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 2.3. ROUGE\n",
    "\n",
    "ROUGE is the Recall-Oriented Understudy for Gisting Evaluation. Its main metrics are:\n",
    "- ROUGE-N (N-gram)\n",
    "- ROUGE-L (Longest Common Subsequence)\n",
    "- ROUGE-S (Skip-gram concurrence metric)\n",
    "\n",
    "It's derived from BLEU - focuses on recall rather than precision, so it looks at how many n-grams in the reference translation show up in the output, rather than the reverse.\n",
    "\n",
    "**We'll use ROUGE-1 (with f1-score) and also ROUGE-L.**\n",
    "We focus on the f1-score because it's a more reliable measure for our model performance, as it relies not only on the model capturing as many words as possible (recall) but doing so without outputting irrelevant words (precision).\n",
    "\n",
    "Notes -> Sentence-level: Compute longest common subsequence (LCS) between two pieces of text. Newlines are ignored. This is called rougeL in this package.\n",
    "\n",
    "https://github.com/pltrdy/rouge/blob/master/rouge/rouge.py\n",
    "\n",
    "`pip install rouge`\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def rouge_sc(df, ref, trans):\n",
    "    \n",
    "    reference = df[ref].to_list()\n",
    "    translation = df[trans].to_list()\n",
    "    \n",
    "    rouge = Rouge(stats=[\"f\"])\n",
    "\n",
    "    rouge_results = rouge.get_scores(translation, reference, avg=False)\n",
    "\n",
    "    rouge_1 = []\n",
    "    rouge_l = []\n",
    "\n",
    "    for i in tqdm(range(len(rouge_results))):\n",
    "        rouge_1.append(rouge_results[i]['rouge-1']['f'])\n",
    "        rouge_l.append(rouge_results[i]['rouge-l']['f'])\n",
    "\n",
    "    return rouge_1, rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1785d95cbc4e9991802bd687cc70f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0128fc7ab032457c841f7868349ca93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accc182f68b545a1a87ea75f579e57a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26418.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d4e45a52e145b4ace02542dd7f8dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26418.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995dda8e61d84654a2f2550aac3b6ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9798b48865c451fbd483481207446e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying ROUGE-1 and ROUGE-L for both Preprocessings for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['rouge-1_1'], i['rouge-l_1'] = rouge_sc(i, \"clean_reference_1\", \"clean_translation_1\")\n",
    "    i['rouge-1_2'], i['rouge-l_2'] = rouge_sc(i, \"clean_reference_2\", \"clean_translation_2\")\n",
    "    \n",
    "    \n",
    "# Applying ROUGE-1 and ROUGE-L for en-zh language pair\n",
    "    \n",
    "en_zh['rouge-1'], en_zh['rouge-l'] = rouge_sc(en_zh, \"clean_reference\", \"clean_translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 2.4. TER\n",
    "The Translation Error Rate, measures the number of edits (words deletion, addition and substitution) needed to change the original output translation into an acceptable human-level translation (match the closest reference translation in fluency and semantics).\n",
    "It is generally preferred to BLEU for estimation of sentence post-editing effort.\n",
    "\n",
    "TER = $\\frac{E}{R}$ = (minimum number of edits) / (average length of reference text)\n",
    "\n",
    "<b>Note:</b> TERp, or TER-plus, is an extension of TER that also considers paraphrases, stemming, and synonyms.\n",
    "\n",
    "    \n",
    "https://blog.taus.net/automated-mt-evaluation-metrics#:~:text=Translation%20Error%20Rate%20(TER)%20is,into%20a%20human%20translated%20reference\n",
    "\n",
    "https://pypi.org/project/pyter3/#description\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyter3\n",
    "import pyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ter_sc(df, ref, trans):\n",
    "    \n",
    "    translation = df[trans].to_list()\n",
    "    reference = df[ref].to_list()\n",
    "    \n",
    "    ter = []\n",
    "\n",
    "    # This function requires the text to be split\n",
    "    for i in tqdm(range(len(translation))):\n",
    "        ter.append(pyter.ter(translation[i].split(), reference[i].split()))\n",
    "        \n",
    "    return ter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying TER for both Preprocessings for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['ter_1'] = ter_sc(i, 'clean_reference_1', 'clean_translation_1')\n",
    "    i['ter_2'] = ter_sc(i, 'clean_reference_2', 'clean_translation_2')\n",
    "\n",
    "    \n",
    "# Applying TER for en-zh language pair\n",
    "    \n",
    "en_zh['ter'] = ter_sc(en_zh, 'clean_reference', 'clean_translation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 2.5. CHRF\n",
    "(Character n-gram F-score) computes the precision, recall and fscore from the ngram overlaps. It returns the support which is the true positive score.\n",
    "\n",
    "By underspecifying the input type, the function will be agnostic as to how it computes the ngrams and simply take the whichever element in the list; it could be either token or character.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.chrf_score import sentence_chrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying CHRF for both Preprocessings for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['chrf_1'] = i.apply(lambda row: sentence_chrf([row['clean_reference_1']],row['clean_translation_1']), axis=1)\n",
    "    i['chrf_2'] = i.apply(lambda row: sentence_chrf([row['clean_reference_2']],row['clean_translation_2']), axis=1)\n",
    "\n",
    "    \n",
    "# Applying CHRF for en-zh language pair\n",
    "    \n",
    "en_zh['chrf'] = en_zh.apply(lambda row: sentence_chrf([row['clean_reference']],row['clean_translation']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 3. More Complex Metrics</font> <a class=\"anchor\" id=\"da\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 3.1. METEOR\n",
    "METEOR (Metric for Evaluation of Translation with Explicit ORdering) is similar to BLEU, but more advanced.\n",
    "\n",
    "The metric is based on the harmonic mean of unigram precision and recall, with recall weighted higher than precision. It also has several features that are not found in other metrics: considers synonyms and compares the stems of words, along with the standard exact word matching. \n",
    "\n",
    "The metric was designed to fix some of the problems found in the more popular BLEU metric, and also produce good correlation with human judgement at the sentence or segment level. This differs from the BLEU metric in that BLEU seeks correlation at the corpus level.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteor_sc(df, ref, trans):\n",
    "    \n",
    "    translation = df[ref].to_list()\n",
    "    reference = df[trans].to_list()\n",
    "    \n",
    "    meteor = []\n",
    "\n",
    "    for i in tqdm(range(len(translation))):\n",
    "        meteor.append(meteor_score.single_meteor_score(reference[i], translation[i]))\n",
    "\n",
    "    return meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f5fe027c8d4393b7f3eed9d091a61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d76333f0a6d4f73b48d50c6dda471a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79a821b1b124b199e3fb7b37f691f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a67669b2464ebdadeb26478d2dcbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4701810d5b1e4d458c31eebaae877b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a257f56e724e27a3e08c139ad337cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35615dd084f44b05b9f02d211cfede90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d0cb304de84a5bbffdf518fa735b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c721be17a79641babf901f9c78f177d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c387aee7ff402387e8f8b04afd3111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6692fa2493b44ce898ebb856cfb6373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying METEOR for both Preprocessings for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['meteor_1'] = meteor_sc(i, \"clean_reference_1\", \"clean_translation_1\")\n",
    "    i['meteor_2'] = meteor_sc(i, \"clean_reference_2\", \"clean_translation_2\")\n",
    "\n",
    "    \n",
    "# Applying METEOR for en-zh language pair\n",
    "    \n",
    "en_zh['meteor'] = meteor_sc(en_zh, \"clean_reference\", \"clean_translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 3.2. BERTscore\n",
    "    \n",
    "BERTScore is an automatic evaluation metric for text generation. It computes a similarity score for each token in the candidate sentence with each token in the reference sentence, but, instead of exact matches, it computes token similarity using contextual embeddings. \n",
    "\n",
    "BERTScore is more robust, correlates better with human judgments and provides stronger model selection performance than existing metrics.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert-score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sc(df, ref, trans, language):\n",
    "    references = df[ref].to_list()\n",
    "    translations = df[trans].to_list()\n",
    "\n",
    "    prec_bert, recall_bert, f1_bert = score(cands=translations, refs=references, lang=language, verbose=True)\n",
    "    \n",
    "    return f1_bert\n",
    "\n",
    "# Here it's not computationally feasible to run all files in a loop as for the other methods, so they're run one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4df3e35cb140c59b1b98e7ae0754af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=191.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2500d1502e42449db87d3bf52cbb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 274.72 seconds, 37.21 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Applying BERT for the en-zh language pair\n",
    "\n",
    "en_zh['bert'] = bert_sc(en_zh, \"clean_reference\", \"clean_translation\",'zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a35ff03ed5946a6a92bde688f7f362d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ecb62df8fa428388ed3b937e681bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 131.52 seconds, 51.31 sentences/sec\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91ab2064d7846e58f951c1bfd31addd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2018072b8d443e9a9719e41eab84227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 137.15 seconds, 49.20 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Applying BERT for the en-fi language pair\n",
    "\n",
    "en_fi['bert_1'] = bert_sc(en_fi, \"clean_reference_1\", \"clean_translation_1\", 'others')\n",
    "en_fi['bert_2'] = bert_sc(en_fi, \"clean_reference_2\", \"clean_translation_2\", 'others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bbecdee5c74bf8a10db46ab3e176f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 2.00 GiB total capacity; 1.16 GiB already allocated; 86.93 MiB free; 1.34 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c585a19209bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcs_en\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bert_1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_sc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs_en\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"clean_reference_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"clean_translation_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# cs_en['bert_2'] = bert_sc(cs_en, \"clean_reference_2\", \"clean_translation_2\", 'en')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e71d20b9d230>\u001b[0m in \u001b[0;36mbert_sc\u001b[1;34m(df, ref, trans, language)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtranslations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprec_bert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_bert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf1_bert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\score.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"calculating scores...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[1;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msen_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         embs, masks, padded_idf = get_bert_embedding(\n\u001b[0m\u001b[0;32m    499\u001b[0m             \u001b[0msen_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mget_bert_embedding\u001b[1;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_sens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m             batch_embedding = bert_encode(\n\u001b[0m\u001b[0;32m    380\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded_sens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mbert_encode\u001b[1;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    688\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         )\n\u001b[1;32m--> 690\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    691\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    423\u001b[0m                 )\n\u001b[0;32m    424\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    426\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add cross attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    370\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1700\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mGELUs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1606.08415\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \"\"\"\n\u001b[1;32m-> 1126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 2.00 GiB total capacity; 1.16 GiB already allocated; 86.93 MiB free; 1.34 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# After the first two language pairs, BERTscore could not be run, so we were not able to use it in our analysis\n",
    "\n",
    "cs_en['bert_1'] = bert_sc(cs_en, \"clean_reference_1\", \"clean_translation_1\", 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 3.3. GLEU - Google-BLEU\n",
    "\n",
    "For the GLEU score, we record all sub-sequences of 1, 2, 3 or 4 tokens in output and target sequence (n-grams). We then compute a recall, which is the ratio of the number of matching n-grams to the number of total n-grams in the target (ground truth) sequence, and a precision, which is the ratio of the number of matching n-grams to the number of total n-grams in the generated output sequence. Then GLEU score is simply the minimum of recall and precision. This GLEU score’s range is always between 0\n",
    "(no matches) and 1 (all match) and it is symmetrical when switching output and target. According to our experiments, GLEU score correlates quite well with the BLEU metric on a corpus level but does not have its drawbacks for our per sentence reward objective.\n",
    "\n",
    "https://github.com/gcunhase/NLPMetrics/blob/master/notebooks/gleu.ipynb\n",
    "\n",
    "https://arxiv.org/pdf/1609.08144.pdf\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.gleu_score as gleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying GLEU for both Preprocessings for all language pairs except en-zh\n",
    "\n",
    "for i in [en_fi, cs_en, ru_en, zh_en, de_en]:\n",
    "    i['gleu_1'] = i.apply(lambda row: gleu.sentence_gleu([row['clean_reference_1']],row['clean_translation_1']), axis=1)\n",
    "    i['gleu_2'] = i.apply(lambda row: gleu.sentence_gleu([row['clean_reference_2']],row['clean_translation_2']), axis=1)\n",
    "    \n",
    "    \n",
    "# Applying GLEU for en-zh language pair\n",
    "    \n",
    "en_zh['gleu'] = en_zh.apply(lambda row: gleu.sentence_gleu([row['clean_reference']],row['clean_translation']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving into new csv's the corpora with all metrics to facilitate their usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_fi.to_csv('en_fi_new.csv')\n",
    "# cs_en.to_csv('cs_en_new.csv')\n",
    "# ru_en.to_csv('ru_en_new.csv')\n",
    "# zh_en.to_csv('zh_en_new.csv')\n",
    "# en_zh.to_csv('en_zh_new.csv')\n",
    "# de_en.to_csv('de_en_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 4. Creation of Train/Dev Split</font> <a class=\"anchor\" id=\"trdv\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fi, cs_en, en_zh, ru_en, zh_en, de_en = pd.read_csv(\"en_fi_new.csv\"), pd.read_csv(\"cs_en_new.csv\"), pd.read_csv(\"en_zh_new.csv\"), pd.read_csv(\"ru_en_new.csv\"), pd.read_csv(\"zh_en_new.csv\"), pd.read_csv(\"de_en_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> All english translations together <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all = pd.concat([cs_en, ru_en, zh_en, de_en])\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54377, 23305)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish split <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fi, dev_fi = train_test_split(en_fi, test_size=0.3, random_state=42, shuffle=True)\n",
    "train_fi.reset_index(inplace=True, drop=True)\n",
    "dev_fi.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4723, 2025)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_fi), len(dev_fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese split <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh, dev_zh = train_test_split(en_zh, test_size=0.3, random_state=42, shuffle=True)\n",
    "train_zh.reset_index(inplace=True, drop=True)\n",
    "dev_zh.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7154, 3067)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_zh), len(dev_zh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 5. Models with Bag of Words</font> <a class=\"anchor\" id=\"bow\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English BoW <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(\n",
    "    max_df=0.8,\n",
    "    stop_words=None,\n",
    "    max_features=10000, \n",
    "    ngram_range=(1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the reference and translation in a single BoW, both for training and development set\n",
    "trans_ref_train = (train.clean_reference_1 + train.clean_translation_1).to_list()\n",
    "trans_ref_dev = (dev.clean_reference_1 + dev.clean_translation_1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54377, 10000)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train = cv.fit_transform(trans_ref_train)\n",
    "bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23305, 10000)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dev = cv.transform(trans_ref_dev)\n",
    "bow_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish BoW <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing all the same for the Finnish translation corpus\n",
    "\n",
    "cv_fi = CountVectorizer(\n",
    "    max_df=0.8,\n",
    "    stop_words=None,\n",
    "    max_features=10000, \n",
    "    ngram_range=(1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_ref_train_fi = (train_fi.clean_reference_1 + train_fi.clean_translation_1).to_list()\n",
    "trans_ref_dev_fi = (dev_fi.clean_reference_1 + dev_fi.clean_translation_1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4723, 10000)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train_fi = cv_fi.fit_transform(trans_ref_train_fi)\n",
    "bow_train_fi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 10000)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dev_fi = cv_fi.transform(trans_ref_dev_fi)\n",
    "bow_dev_fi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese BoW <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing all the same for the Chinese translation corpus\n",
    "\n",
    "cv_zh = CountVectorizer(\n",
    "    max_df=0.8,\n",
    "    stop_words=None,\n",
    "    max_features=10000, \n",
    "    ngram_range=(1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_ref_train_zh = (train_zh.clean_reference + train_zh.clean_translation).to_list()\n",
    "trans_ref_dev_zh = (dev_zh.clean_reference + dev_zh.clean_translation).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7154, 10000)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train_zh = cv_zh.fit_transform(trans_ref_train_zh)\n",
    "bow_train_zh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 10000)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dev_zh = cv_zh.transform(trans_ref_dev_zh)\n",
    "bow_dev_zh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Neural Networks (Sklearn)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English NN <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes=(10,10) ,random_state=42, max_iter=50, alpha=0.01).fit(bow_train, train['z-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = regr.predict(bow_train)\n",
    "pred_dev = regr.predict(bow_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.425469736865002 \n",
      "Dev: 0.9779057685676135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(train['z-score'], pred_train, squared=False)\n",
    "print('Train:',mean_squared_error(train['z-score'], pred_train, squared=False),'\\nDev:',mean_squared_error(dev['z-score'], pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NN_bow'] = pred_train\n",
    "dev['NN_bow'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish NN <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_fi = MLPRegressor(hidden_layer_sizes=(10,10) ,random_state=42, max_iter=50, alpha=0.01).fit(bow_train_fi, train_fi['z-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_fi = regr_fi.predict(bow_train_fi)\n",
    "pred_dev_fi = regr_fi.predict(bow_dev_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.18256874535946918 \n",
      "Dev: 0.9883580176079034\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error(train['z-score'], pred_train, squared=False)\n",
    "print('Train:',mean_squared_error(train_fi['z-score'], pred_train_fi, squared=False),'\\nDev:',mean_squared_error(dev_fi['z-score'], pred_dev_fi, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fi['NN_bow'] = pred_train_fi\n",
    "dev_fi['NN_bow'] = pred_dev_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese NN <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_zh = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(bow_train_zh, train_zh['z-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_zh = regr_zh.predict(bow_train_zh)\n",
    "pred_dev_zh = regr_zh.predict(bow_dev_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6464679058498025 \n",
      "Dev: 0.9186680390548998\n"
     ]
    }
   ],
   "source": [
    "print('Train:',mean_squared_error(train_zh['z-score'], pred_train_zh, squared=False),'\\nDev:',mean_squared_error(dev_zh['z-score'], pred_dev_zh, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh['NN_bow'] = pred_train_zh\n",
    "dev_zh['NN_bow'] = pred_dev_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Deep Learning (Keras)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1700/1700 - 95s - loss: 0.7280 - root_mean_squared_error: 0.8532 - val_loss: 0.6958 - val_root_mean_squared_error: 0.8342\n",
      "Epoch 2/30\n",
      "1700/1700 - 153s - loss: 0.6669 - root_mean_squared_error: 0.8167 - val_loss: 0.6869 - val_root_mean_squared_error: 0.8288\n",
      "Epoch 3/30\n",
      "1700/1700 - 100s - loss: 0.6227 - root_mean_squared_error: 0.7891 - val_loss: 0.6933 - val_root_mean_squared_error: 0.8327\n",
      "Epoch 4/30\n",
      "1700/1700 - 32s - loss: 0.5845 - root_mean_squared_error: 0.7645 - val_loss: 0.6986 - val_root_mean_squared_error: 0.8358\n",
      "Epoch 5/30\n",
      "1700/1700 - 62s - loss: 0.5504 - root_mean_squared_error: 0.7419 - val_loss: 0.6902 - val_root_mean_squared_error: 0.8308\n",
      "Epoch 6/30\n",
      "1700/1700 - 62s - loss: 0.5164 - root_mean_squared_error: 0.7186 - val_loss: 0.6954 - val_root_mean_squared_error: 0.8339\n",
      "Epoch 7/30\n",
      "1700/1700 - 37s - loss: 0.4863 - root_mean_squared_error: 0.6973 - val_loss: 0.7276 - val_root_mean_squared_error: 0.8530\n",
      "Epoch 8/30\n",
      "1700/1700 - 109s - loss: 0.4576 - root_mean_squared_error: 0.6765 - val_loss: 0.7349 - val_root_mean_squared_error: 0.8572\n",
      "Epoch 9/30\n",
      "1700/1700 - 79s - loss: 0.4331 - root_mean_squared_error: 0.6581 - val_loss: 0.7374 - val_root_mean_squared_error: 0.8587\n",
      "Epoch 10/30\n",
      "1700/1700 - 93s - loss: 0.4083 - root_mean_squared_error: 0.6389 - val_loss: 0.7751 - val_root_mean_squared_error: 0.8804\n",
      "Epoch 11/30\n",
      "1700/1700 - 69s - loss: 0.3879 - root_mean_squared_error: 0.6229 - val_loss: 0.7585 - val_root_mean_squared_error: 0.8709\n",
      "Epoch 12/30\n",
      "1700/1700 - 60s - loss: 0.3656 - root_mean_squared_error: 0.6046 - val_loss: 0.7624 - val_root_mean_squared_error: 0.8732\n",
      "Epoch 13/30\n",
      "1700/1700 - 54s - loss: 0.3486 - root_mean_squared_error: 0.5904 - val_loss: 0.7852 - val_root_mean_squared_error: 0.8861\n",
      "Epoch 14/30\n",
      "1700/1700 - 64s - loss: 0.3345 - root_mean_squared_error: 0.5783 - val_loss: 0.7924 - val_root_mean_squared_error: 0.8902\n",
      "Epoch 15/30\n",
      "1700/1700 - 57s - loss: 0.3181 - root_mean_squared_error: 0.5640 - val_loss: 0.8024 - val_root_mean_squared_error: 0.8957\n",
      "Epoch 16/30\n",
      "1700/1700 - 53s - loss: 0.3067 - root_mean_squared_error: 0.5538 - val_loss: 0.7920 - val_root_mean_squared_error: 0.8900\n",
      "Epoch 17/30\n",
      "1700/1700 - 78s - loss: 0.2944 - root_mean_squared_error: 0.5426 - val_loss: 0.8137 - val_root_mean_squared_error: 0.9021\n",
      "Epoch 18/30\n",
      "1700/1700 - 113s - loss: 0.2840 - root_mean_squared_error: 0.5329 - val_loss: 0.8143 - val_root_mean_squared_error: 0.9024\n",
      "Epoch 19/30\n",
      "1700/1700 - 262s - loss: 0.2716 - root_mean_squared_error: 0.5211 - val_loss: 0.8287 - val_root_mean_squared_error: 0.9103\n",
      "Epoch 20/30\n",
      "1700/1700 - 78s - loss: 0.2628 - root_mean_squared_error: 0.5126 - val_loss: 0.8386 - val_root_mean_squared_error: 0.9158\n",
      "Epoch 21/30\n",
      "1700/1700 - 56s - loss: 0.2534 - root_mean_squared_error: 0.5034 - val_loss: 0.8455 - val_root_mean_squared_error: 0.9195\n",
      "Epoch 22/30\n",
      "1700/1700 - 54s - loss: 0.2453 - root_mean_squared_error: 0.4952 - val_loss: 0.8306 - val_root_mean_squared_error: 0.9113\n",
      "Epoch 23/30\n",
      "1700/1700 - 108s - loss: 0.2378 - root_mean_squared_error: 0.4877 - val_loss: 0.8707 - val_root_mean_squared_error: 0.9331\n",
      "Epoch 24/30\n",
      "1700/1700 - 173s - loss: 0.2328 - root_mean_squared_error: 0.4825 - val_loss: 0.8491 - val_root_mean_squared_error: 0.9215\n",
      "Epoch 25/30\n",
      "1700/1700 - 77s - loss: 0.2251 - root_mean_squared_error: 0.4745 - val_loss: 0.8601 - val_root_mean_squared_error: 0.9274\n",
      "Epoch 26/30\n",
      "1700/1700 - 126s - loss: 0.2195 - root_mean_squared_error: 0.4685 - val_loss: 0.8758 - val_root_mean_squared_error: 0.9358\n",
      "Epoch 27/30\n",
      "1700/1700 - 77s - loss: 0.2142 - root_mean_squared_error: 0.4628 - val_loss: 0.8680 - val_root_mean_squared_error: 0.9316\n",
      "Epoch 28/30\n",
      "1700/1700 - 55s - loss: 0.2077 - root_mean_squared_error: 0.4558 - val_loss: 0.8921 - val_root_mean_squared_error: 0.9445\n",
      "Epoch 29/30\n",
      "1700/1700 - 58s - loss: 0.2027 - root_mean_squared_error: 0.4503 - val_loss: 0.8600 - val_root_mean_squared_error: 0.9274\n",
      "Epoch 30/30\n",
      "1700/1700 - 195s - loss: 0.1986 - root_mean_squared_error: 0.4456 - val_loss: 0.8778 - val_root_mean_squared_error: 0.9369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfb646bf10>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = bow_train.toarray().shape[1]\n",
    "\n",
    "# define network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(n_words,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model.fit(bow_train.toarray(), train['z-score'], epochs=30, verbose=2,validation_data=(bow_dev.toarray(), dev['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.936933\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, rmse = model.evaluate(bow_dev.toarray(), dev['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DL_bow'] = model.predict(bow_train.toarray())\n",
    "dev['DL_bow'] = model.predict(bow_dev.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "148/148 - 6s - loss: 0.7253 - root_mean_squared_error: 0.8516 - val_loss: 0.6960 - val_root_mean_squared_error: 0.8343\n",
      "Epoch 2/30\n",
      "148/148 - 3s - loss: 0.5229 - root_mean_squared_error: 0.7231 - val_loss: 0.6950 - val_root_mean_squared_error: 0.8337\n",
      "Epoch 3/30\n",
      "148/148 - 3s - loss: 0.4176 - root_mean_squared_error: 0.6462 - val_loss: 0.6927 - val_root_mean_squared_error: 0.8323\n",
      "Epoch 4/30\n",
      "148/148 - 3s - loss: 0.3432 - root_mean_squared_error: 0.5859 - val_loss: 0.7371 - val_root_mean_squared_error: 0.8586\n",
      "Epoch 5/30\n",
      "148/148 - 2s - loss: 0.2905 - root_mean_squared_error: 0.5390 - val_loss: 0.7260 - val_root_mean_squared_error: 0.8520\n",
      "Epoch 6/30\n",
      "148/148 - 2s - loss: 0.2480 - root_mean_squared_error: 0.4980 - val_loss: 0.7267 - val_root_mean_squared_error: 0.8525\n",
      "Epoch 7/30\n",
      "148/148 - 2s - loss: 0.2155 - root_mean_squared_error: 0.4642 - val_loss: 0.7952 - val_root_mean_squared_error: 0.8917\n",
      "Epoch 8/30\n",
      "148/148 - 2s - loss: 0.1887 - root_mean_squared_error: 0.4344 - val_loss: 0.7812 - val_root_mean_squared_error: 0.8839\n",
      "Epoch 9/30\n",
      "148/148 - 2s - loss: 0.1684 - root_mean_squared_error: 0.4104 - val_loss: 0.7888 - val_root_mean_squared_error: 0.8881\n",
      "Epoch 10/30\n",
      "148/148 - 2s - loss: 0.1541 - root_mean_squared_error: 0.3926 - val_loss: 0.7728 - val_root_mean_squared_error: 0.8791\n",
      "Epoch 11/30\n",
      "148/148 - 2s - loss: 0.1391 - root_mean_squared_error: 0.3729 - val_loss: 0.7933 - val_root_mean_squared_error: 0.8907\n",
      "Epoch 12/30\n",
      "148/148 - 2s - loss: 0.1325 - root_mean_squared_error: 0.3640 - val_loss: 0.7849 - val_root_mean_squared_error: 0.8860\n",
      "Epoch 13/30\n",
      "148/148 - 2s - loss: 0.1221 - root_mean_squared_error: 0.3494 - val_loss: 0.7854 - val_root_mean_squared_error: 0.8862\n",
      "Epoch 14/30\n",
      "148/148 - 2s - loss: 0.1129 - root_mean_squared_error: 0.3359 - val_loss: 0.7873 - val_root_mean_squared_error: 0.8873\n",
      "Epoch 15/30\n",
      "148/148 - 2s - loss: 0.1041 - root_mean_squared_error: 0.3226 - val_loss: 0.8262 - val_root_mean_squared_error: 0.9090\n",
      "Epoch 16/30\n",
      "148/148 - 2s - loss: 0.0988 - root_mean_squared_error: 0.3143 - val_loss: 0.8179 - val_root_mean_squared_error: 0.9044\n",
      "Epoch 17/30\n",
      "148/148 - 2s - loss: 0.0935 - root_mean_squared_error: 0.3057 - val_loss: 0.7970 - val_root_mean_squared_error: 0.8927\n",
      "Epoch 18/30\n",
      "148/148 - 2s - loss: 0.0901 - root_mean_squared_error: 0.3002 - val_loss: 0.7910 - val_root_mean_squared_error: 0.8894\n",
      "Epoch 19/30\n",
      "148/148 - 2s - loss: 0.0859 - root_mean_squared_error: 0.2931 - val_loss: 0.8002 - val_root_mean_squared_error: 0.8945\n",
      "Epoch 20/30\n",
      "148/148 - 2s - loss: 0.0795 - root_mean_squared_error: 0.2820 - val_loss: 0.8023 - val_root_mean_squared_error: 0.8957\n",
      "Epoch 21/30\n",
      "148/148 - 2s - loss: 0.0785 - root_mean_squared_error: 0.2802 - val_loss: 0.8011 - val_root_mean_squared_error: 0.8951\n",
      "Epoch 22/30\n",
      "148/148 - 2s - loss: 0.0743 - root_mean_squared_error: 0.2726 - val_loss: 0.8146 - val_root_mean_squared_error: 0.9026\n",
      "Epoch 23/30\n",
      "148/148 - 3s - loss: 0.0710 - root_mean_squared_error: 0.2664 - val_loss: 0.8161 - val_root_mean_squared_error: 0.9034\n",
      "Epoch 24/30\n",
      "148/148 - 2s - loss: 0.0707 - root_mean_squared_error: 0.2659 - val_loss: 0.8083 - val_root_mean_squared_error: 0.8991\n",
      "Epoch 25/30\n",
      "148/148 - 2s - loss: 0.0675 - root_mean_squared_error: 0.2598 - val_loss: 0.8335 - val_root_mean_squared_error: 0.9130\n",
      "Epoch 26/30\n",
      "148/148 - 2s - loss: 0.0643 - root_mean_squared_error: 0.2535 - val_loss: 0.8248 - val_root_mean_squared_error: 0.9082\n",
      "Epoch 27/30\n",
      "148/148 - 2s - loss: 0.0651 - root_mean_squared_error: 0.2552 - val_loss: 0.8148 - val_root_mean_squared_error: 0.9026\n",
      "Epoch 28/30\n",
      "148/148 - 3s - loss: 0.0621 - root_mean_squared_error: 0.2491 - val_loss: 0.8100 - val_root_mean_squared_error: 0.9000\n",
      "Epoch 29/30\n",
      "148/148 - 2s - loss: 0.0599 - root_mean_squared_error: 0.2447 - val_loss: 0.8152 - val_root_mean_squared_error: 0.9029\n",
      "Epoch 30/30\n",
      "148/148 - 2s - loss: 0.0579 - root_mean_squared_error: 0.2405 - val_loss: 0.8191 - val_root_mean_squared_error: 0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfb6811e80>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_fi = bow_train_fi.toarray().shape[1]\n",
    "\n",
    "# define network\n",
    "model_fi = Sequential()\n",
    "model_fi.add(Dense(64, input_shape=(n_words_fi,), activation='relu'))\n",
    "model_fi.add(Dense(64, activation='relu'))\n",
    "model_fi.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_fi.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_fi.fit(bow_train_fi.toarray(), train_fi['z-score'], epochs=30, verbose=2,validation_data=(bow_dev_fi.toarray(), dev_fi['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.905059\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, rmse = model_fi.evaluate(bow_dev_fi.toarray(), dev_fi['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fi['DL_bow'] = model_fi.predict(bow_train_fi.toarray())\n",
    "dev_fi['DL_bow'] = model_fi.predict(bow_dev_fi.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "224/224 - 6s - loss: 0.8314 - root_mean_squared_error: 0.9118 - val_loss: 0.7860 - val_root_mean_squared_error: 0.8866\n",
      "Epoch 2/30\n",
      "224/224 - 4s - loss: 0.6931 - root_mean_squared_error: 0.8325 - val_loss: 0.7693 - val_root_mean_squared_error: 0.8771\n",
      "Epoch 3/30\n",
      "224/224 - 4s - loss: 0.6382 - root_mean_squared_error: 0.7989 - val_loss: 0.7769 - val_root_mean_squared_error: 0.8814\n",
      "Epoch 4/30\n",
      "224/224 - 4s - loss: 0.6101 - root_mean_squared_error: 0.7811 - val_loss: 0.7687 - val_root_mean_squared_error: 0.8767\n",
      "Epoch 5/30\n",
      "224/224 - 4s - loss: 0.5942 - root_mean_squared_error: 0.7708 - val_loss: 0.7764 - val_root_mean_squared_error: 0.8811\n",
      "Epoch 6/30\n",
      "224/224 - 4s - loss: 0.5822 - root_mean_squared_error: 0.7630 - val_loss: 0.7710 - val_root_mean_squared_error: 0.8781\n",
      "Epoch 7/30\n",
      "224/224 - 4s - loss: 0.5716 - root_mean_squared_error: 0.7560 - val_loss: 0.7875 - val_root_mean_squared_error: 0.8874\n",
      "Epoch 8/30\n",
      "224/224 - 4s - loss: 0.5644 - root_mean_squared_error: 0.7512 - val_loss: 0.7790 - val_root_mean_squared_error: 0.8826\n",
      "Epoch 9/30\n",
      "224/224 - 4s - loss: 0.5581 - root_mean_squared_error: 0.7471 - val_loss: 0.7746 - val_root_mean_squared_error: 0.8801\n",
      "Epoch 10/30\n",
      "224/224 - 4s - loss: 0.5512 - root_mean_squared_error: 0.7424 - val_loss: 0.8079 - val_root_mean_squared_error: 0.8988\n",
      "Epoch 11/30\n",
      "224/224 - 4s - loss: 0.5484 - root_mean_squared_error: 0.7406 - val_loss: 0.7746 - val_root_mean_squared_error: 0.8801\n",
      "Epoch 12/30\n",
      "224/224 - 4s - loss: 0.5428 - root_mean_squared_error: 0.7367 - val_loss: 0.7813 - val_root_mean_squared_error: 0.8839\n",
      "Epoch 13/30\n",
      "224/224 - 4s - loss: 0.5410 - root_mean_squared_error: 0.7355 - val_loss: 0.7863 - val_root_mean_squared_error: 0.8867\n",
      "Epoch 14/30\n",
      "224/224 - 5s - loss: 0.5335 - root_mean_squared_error: 0.7304 - val_loss: 0.7860 - val_root_mean_squared_error: 0.8866\n",
      "Epoch 15/30\n",
      "224/224 - 4s - loss: 0.5324 - root_mean_squared_error: 0.7297 - val_loss: 0.7911 - val_root_mean_squared_error: 0.8894\n",
      "Epoch 16/30\n",
      "224/224 - 4s - loss: 0.5299 - root_mean_squared_error: 0.7279 - val_loss: 0.7859 - val_root_mean_squared_error: 0.8865\n",
      "Epoch 17/30\n",
      "224/224 - 4s - loss: 0.5260 - root_mean_squared_error: 0.7252 - val_loss: 0.7968 - val_root_mean_squared_error: 0.8927\n",
      "Epoch 18/30\n",
      "224/224 - 4s - loss: 0.5245 - root_mean_squared_error: 0.7242 - val_loss: 0.7885 - val_root_mean_squared_error: 0.8880\n",
      "Epoch 19/30\n",
      "224/224 - 4s - loss: 0.5209 - root_mean_squared_error: 0.7218 - val_loss: 0.7828 - val_root_mean_squared_error: 0.8848\n",
      "Epoch 20/30\n",
      "224/224 - 4s - loss: 0.5197 - root_mean_squared_error: 0.7209 - val_loss: 0.7880 - val_root_mean_squared_error: 0.8877\n",
      "Epoch 21/30\n",
      "224/224 - 4s - loss: 0.5164 - root_mean_squared_error: 0.7186 - val_loss: 0.7873 - val_root_mean_squared_error: 0.8873\n",
      "Epoch 22/30\n",
      "224/224 - 4s - loss: 0.5143 - root_mean_squared_error: 0.7171 - val_loss: 0.7947 - val_root_mean_squared_error: 0.8915\n",
      "Epoch 23/30\n",
      "224/224 - 4s - loss: 0.5120 - root_mean_squared_error: 0.7156 - val_loss: 0.8021 - val_root_mean_squared_error: 0.8956\n",
      "Epoch 24/30\n",
      "224/224 - 4s - loss: 0.5102 - root_mean_squared_error: 0.7143 - val_loss: 0.7931 - val_root_mean_squared_error: 0.8906\n",
      "Epoch 25/30\n",
      "224/224 - 4s - loss: 0.5080 - root_mean_squared_error: 0.7128 - val_loss: 0.7998 - val_root_mean_squared_error: 0.8943\n",
      "Epoch 26/30\n",
      "224/224 - 4s - loss: 0.5054 - root_mean_squared_error: 0.7109 - val_loss: 0.7987 - val_root_mean_squared_error: 0.8937\n",
      "Epoch 27/30\n",
      "224/224 - 4s - loss: 0.5049 - root_mean_squared_error: 0.7105 - val_loss: 0.8000 - val_root_mean_squared_error: 0.8944\n",
      "Epoch 28/30\n",
      "224/224 - 4s - loss: 0.5030 - root_mean_squared_error: 0.7092 - val_loss: 0.8261 - val_root_mean_squared_error: 0.9089\n",
      "Epoch 29/30\n",
      "224/224 - 4s - loss: 0.5013 - root_mean_squared_error: 0.7080 - val_loss: 0.7864 - val_root_mean_squared_error: 0.8868\n",
      "Epoch 30/30\n",
      "224/224 - 4s - loss: 0.5009 - root_mean_squared_error: 0.7077 - val_loss: 0.8164 - val_root_mean_squared_error: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfbfa6c130>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_zh = bow_train_zh.toarray().shape[1]\n",
    "\n",
    "# define network\n",
    "model_zh = Sequential()\n",
    "model_zh.add(Dense(64, input_shape=(n_words,), activation='relu'))\n",
    "model_zh.add(Dense(64, activation='relu'))\n",
    "model_zh.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_zh.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_zh.fit(bow_train_zh.toarray(), train_zh['z-score'], epochs=30, verbose=2,validation_data=(bow_dev_zh.toarray(), dev_zh['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.903543\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, rmse = model_zh.evaluate(bow_dev_zh.toarray(), dev_zh['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh['DL_bow'] = model_zh.predict(bow_train_zh.toarray())\n",
    "dev_zh['DL_bow'] = model_zh.predict(bow_dev_zh.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 6. Models with Word Embeddings</font> <a class=\"anchor\" id=\"embed\"></a>\n",
    "Done seperately for each language pair.\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_de_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/de-en/laser.reference_embeds.npy', allow_pickle=True)\n",
    "train_source_de_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/de-en/laser.source_embeds.npy', allow_pickle=True)\n",
    "train_trans_de_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/de-en/laser.translation_embeds.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(de_en, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining reference source and translation\n",
    "embed_de_en = np.concatenate((train_ref_de_en, train_source_de_en, train_trans_de_en),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the array to fit the train/dev split\n",
    "train_embed_de_en = embed_de_en[:15192]\n",
    "dev_embed_de_en = embed_de_en[15192:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>cs-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_cs_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/cs-en/laser.reference_embeds.npy', allow_pickle=True)\n",
    "train_source_cs_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/cs-en/laser.source_embeds.npy', allow_pickle=True)\n",
    "train_trans_cs_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/cs-en/laser.translation_embeds.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cs, dev_cs = train_test_split(cs_en, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "train_cs.reset_index(inplace=True, drop=True)\n",
    "dev_cs.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8109"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining reference source and translation in an array\n",
    "embed_cs_en = np.concatenate((train_ref_cs_en, train_source_cs_en, train_trans_cs_en),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the array to fit the train/dev split\n",
    "train_embed_cs_en = embed_cs_en[:8109]\n",
    "dev_embed_cs_en = embed_cs_en[8109:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ru-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_ru_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/ru-en/laser.reference_embeds.npy', allow_pickle=True)\n",
    "train_source_ru_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/ru-en/laser.source_embeds.npy', allow_pickle=True)\n",
    "train_trans_ru_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/ru-en/laser.translation_embeds.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_en = pd.read_csv(\"ru_en_clean.csv\")\n",
    "train_ru, dev_ru = train_test_split(ru_en, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "train_ru.reset_index(inplace=True, drop=True)\n",
    "dev_ru.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12586"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining reference source and translation in an array\n",
    "embed_ru_en = np.concatenate((train_ref_ru_en, train_source_ru_en, train_trans_ru_en),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the array to fit the train/dev split\n",
    "train_embed_ru_en = embed_ru_en[:12586]\n",
    "dev_embed_ru_en = embed_ru_en[12586:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>zh-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_zh_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/zh-en/laser.reference_embeds.npy', allow_pickle=True)\n",
    "train_source_zh_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/zh-en/laser.source_embeds.npy', allow_pickle=True)\n",
    "train_trans_zh_en = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/zh-en/laser.translation_embeds.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_en = pd.read_csv(\"zh_en_clean.csv\")\n",
    "\n",
    "train_zhen, dev_zhen = train_test_split(zh_en, test_size=0.3, random_state=42, shuffle=False)\n",
    "train_zhen.reset_index(inplace=True, drop=True)\n",
    "dev_zhen.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18493"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_zhen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining reference source and translation in an array\n",
    "embed_zh_en = np.concatenate((train_ref_zh_en, train_source_zh_en, train_trans_zh_en),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the array to fit the train/dev split\n",
    "train_embed_zh_en = embed_zh_en[:18493]\n",
    "dev_embed_zh_en = embed_zh_en[18493:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>en-fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_en_fi = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/en-fi/laser.reference_embeds.npy', allow_pickle=True)\n",
    "train_source_en_fi = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/en-fi/laser.source_embeds.npy', allow_pickle=True)\n",
    "train_trans_en_fi = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/en-fi/laser.translation_embeds.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fi, dev_fi = train_test_split(en_fi, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n",
    "train_fi.reset_index(inplace=True, drop=True)\n",
    "dev_fi.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4723"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining reference source and translation in an array\n",
    "embed_en_fi = np.concatenate((train_ref_en_fi, train_source_en_fi, train_trans_en_fi),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the array to fit the train/dev split\n",
    "train_embed_en_fi = embed_en_fi[:4723]\n",
    "dev_embed_en_fi = embed_en_fi[4723:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>en-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref_en_zh = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/en-zh/laser.reference_embeds.npy', allow_pickle=True)\n",
    "train_source_en_zh = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/en-zh/laser.source_embeds.npy', allow_pickle=True)\n",
    "train_trans_en_zh = np.load('C:/Users/matip/Documents/Mestrado/2. Text Mining/Project/corpus/Embeddings/corpus/en-zh/laser.translation_embeds.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enzh, dev_enzh = train_test_split(en_zh, test_size=0.3, random_state=42, shuffle=False)\n",
    "train_enzh.reset_index(inplace=True, drop=True)\n",
    "dev_enzh.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7154"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_enzh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining reference source and translation in an array\n",
    "embed_en_zh = np.concatenate((train_ref_en_zh, train_source_en_zh, train_trans_en_zh),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the array to fit the train/dev split\n",
    "train_embed_en_zh = embed_en_zh[:7154]\n",
    "dev_embed_en_zh = embed_en_zh[7154:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Neural Networks (SkLearn)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_zh = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(train_embed_de_en, train['z-score'])\n",
    "\n",
    "pred_train = regr.predict(train_embed_de_en)\n",
    "pred_dev = regr.predict(dev_embed_de_en)\n",
    "\n",
    "print('Train:',mean_squared_error(train['z-score'], pred_train, squared=False),'\\nDev:',mean_squared_error(dev['z-score'], pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NN_embedded'] = pred_train\n",
    "dev['NN_embedded'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> cs-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.5520173117593772 \n",
      "Dev: 0.800841242261568\n"
     ]
    }
   ],
   "source": [
    "regr_cs = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(train_embed_cs_en, train_cs['z-score'])\n",
    "\n",
    "pred_train_cs = regr_cs.predict(train_embed_cs_en)\n",
    "pred_dev_cs = regr_cs.predict(dev_embed_cs_en)\n",
    "\n",
    "print('Train:',mean_squared_error(train_cs['z-score'], pred_train_cs, squared=False),'\\nDev:',mean_squared_error(dev_cs['z-score'], pred_dev_cs, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cs['NN_embedded'] = pred_train_cs\n",
    "dev_cs['NN_embedded'] = pred_dev_cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> ru-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6775352037724004 \n",
      "Dev: 0.916386646256473\n"
     ]
    }
   ],
   "source": [
    "regr_ru = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(train_embed_ru_en, train_ru['z-score'])\n",
    "\n",
    "pred_train_ru = regr_ru.predict(train_embed_ru_en)\n",
    "pred_dev_ru = regr_ru.predict(dev_embed_ru_en)\n",
    "\n",
    "print('Train:',mean_squared_error(train_ru['z-score'], pred_train_ru, squared=False),'\\nDev:',mean_squared_error(dev_ru['z-score'], pred_dev_ru, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ru['NN_embedded'] = pred_train_ru\n",
    "dev_ru['NN_embedded'] = pred_dev_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> zh-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7057464035860933 \n",
      "Dev: 0.850612245465507\n"
     ]
    }
   ],
   "source": [
    "regr_zhen = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(train_embed_zh_en, train_zhen['z-score'])\n",
    "\n",
    "pred_train_zhen = regr_zhen.predict(train_embed_zh_en)\n",
    "pred_dev_zhen = regr_zhen.predict(dev_embed_zh_en)\n",
    "\n",
    "print('Train:',mean_squared_error(train_zhen['z-score'], pred_train_zhen, squared=False),'\\nDev:',mean_squared_error(dev_zhen['z-score'], pred_dev_zhen, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zhen['NN_embedded'] = pred_train_zhen\n",
    "dev_zhen['NN_embedded'] = pred_dev_zhen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.5672980908017875 \n",
      "Dev: 0.7870533995512707\n"
     ]
    }
   ],
   "source": [
    "regr_fi = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(train_embed_en_fi, train_fi['z-score'])\n",
    "\n",
    "pred_train_fi = regr_fi.predict(train_embed_en_fi)\n",
    "pred_dev_fi = regr_fi.predict(dev_embed_en_fi)\n",
    "\n",
    "print('Train:',mean_squared_error(train_fi['z-score'], pred_train_fi, squared=False),'\\nDev:',mean_squared_error(dev_fi['z-score'], pred_dev_fi, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fi['NN_embedded'] = pred_train_fi\n",
    "dev_fi['NN_embedded'] = pred_dev_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6714207144097877 \n",
      "Dev: 0.8379415212556378\n"
     ]
    }
   ],
   "source": [
    "regr_enzh = MLPRegressor(hidden_layer_sizes=(10,10),random_state=42, max_iter=50, alpha=0.01).fit(train_embed_en_zh, train_enzh['z-score'])\n",
    "\n",
    "pred_train_enzh = regr_enzh.predict(train_embed_en_zh)\n",
    "pred_dev_enzh = regr_enzh.predict(dev_embed_en_zh)\n",
    "\n",
    "print('Train:',mean_squared_error(train_enzh['z-score'], pred_train_enzh, squared=False),'\\nDev:',mean_squared_error(dev_enzh['z-score'], pred_dev_enzh, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enzh['NN_embedded'] = pred_train_enzh\n",
    "dev_enzh['NN_embedded'] = pred_dev_enzh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Deep Learning (Keras)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15192, 3072)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embed_de_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_words = train_embed_de_en.shape[1]\n",
    "\n",
    "# define network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(n_words,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model.fit(train_embed_de_en, train['z-score'], epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.837514\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, rmse = model.evaluate(dev_embed_de_en, dev['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DL_embed'] = model.predict(train_embed_de_en)\n",
    "dev['DL_embed'] = model.predict(dev_embed_de_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> cs-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "254/254 - 2s - loss: 0.7244 - root_mean_squared_error: 0.8511 - val_loss: 0.7687 - val_root_mean_squared_error: 0.8768\n",
      "Epoch 2/30\n",
      "254/254 - 1s - loss: 0.6606 - root_mean_squared_error: 0.8128 - val_loss: 0.7096 - val_root_mean_squared_error: 0.8424\n",
      "Epoch 3/30\n",
      "254/254 - 1s - loss: 0.6085 - root_mean_squared_error: 0.7801 - val_loss: 0.6657 - val_root_mean_squared_error: 0.8159\n",
      "Epoch 4/30\n",
      "254/254 - 1s - loss: 0.5649 - root_mean_squared_error: 0.7516 - val_loss: 0.6512 - val_root_mean_squared_error: 0.8069\n",
      "Epoch 5/30\n",
      "254/254 - 1s - loss: 0.5346 - root_mean_squared_error: 0.7312 - val_loss: 0.6574 - val_root_mean_squared_error: 0.8108\n",
      "Epoch 6/30\n",
      "254/254 - 1s - loss: 0.4996 - root_mean_squared_error: 0.7069 - val_loss: 0.6352 - val_root_mean_squared_error: 0.7970\n",
      "Epoch 7/30\n",
      "254/254 - 1s - loss: 0.4766 - root_mean_squared_error: 0.6904 - val_loss: 0.6443 - val_root_mean_squared_error: 0.8027\n",
      "Epoch 8/30\n",
      "254/254 - 1s - loss: 0.4504 - root_mean_squared_error: 0.6712 - val_loss: 0.6401 - val_root_mean_squared_error: 0.8001\n",
      "Epoch 9/30\n",
      "254/254 - 1s - loss: 0.4311 - root_mean_squared_error: 0.6566 - val_loss: 0.6693 - val_root_mean_squared_error: 0.8181\n",
      "Epoch 10/30\n",
      "254/254 - 1s - loss: 0.4165 - root_mean_squared_error: 0.6454 - val_loss: 0.6261 - val_root_mean_squared_error: 0.7913\n",
      "Epoch 11/30\n",
      "254/254 - 1s - loss: 0.3933 - root_mean_squared_error: 0.6271 - val_loss: 0.6184 - val_root_mean_squared_error: 0.7864\n",
      "Epoch 12/30\n",
      "254/254 - 1s - loss: 0.3726 - root_mean_squared_error: 0.6104 - val_loss: 0.5971 - val_root_mean_squared_error: 0.7728\n",
      "Epoch 13/30\n",
      "254/254 - 1s - loss: 0.3639 - root_mean_squared_error: 0.6032 - val_loss: 0.6009 - val_root_mean_squared_error: 0.7751\n",
      "Epoch 14/30\n",
      "254/254 - 1s - loss: 0.3449 - root_mean_squared_error: 0.5873 - val_loss: 0.6028 - val_root_mean_squared_error: 0.7764\n",
      "Epoch 15/30\n",
      "254/254 - 1s - loss: 0.3395 - root_mean_squared_error: 0.5827 - val_loss: 0.7824 - val_root_mean_squared_error: 0.8846\n",
      "Epoch 16/30\n",
      "254/254 - 1s - loss: 0.3243 - root_mean_squared_error: 0.5695 - val_loss: 0.6348 - val_root_mean_squared_error: 0.7967\n",
      "Epoch 17/30\n",
      "254/254 - 1s - loss: 0.3135 - root_mean_squared_error: 0.5599 - val_loss: 0.6633 - val_root_mean_squared_error: 0.8144\n",
      "Epoch 18/30\n",
      "254/254 - 1s - loss: 0.3023 - root_mean_squared_error: 0.5498 - val_loss: 0.6031 - val_root_mean_squared_error: 0.7766\n",
      "Epoch 19/30\n",
      "254/254 - 1s - loss: 0.2973 - root_mean_squared_error: 0.5452 - val_loss: 0.6301 - val_root_mean_squared_error: 0.7938\n",
      "Epoch 20/30\n",
      "254/254 - 1s - loss: 0.2856 - root_mean_squared_error: 0.5344 - val_loss: 0.6589 - val_root_mean_squared_error: 0.8117\n",
      "Epoch 21/30\n",
      "254/254 - 1s - loss: 0.2796 - root_mean_squared_error: 0.5288 - val_loss: 0.7440 - val_root_mean_squared_error: 0.8626\n",
      "Epoch 22/30\n",
      "254/254 - 1s - loss: 0.2688 - root_mean_squared_error: 0.5185 - val_loss: 0.6107 - val_root_mean_squared_error: 0.7815\n",
      "Epoch 23/30\n",
      "254/254 - 1s - loss: 0.2629 - root_mean_squared_error: 0.5127 - val_loss: 0.7058 - val_root_mean_squared_error: 0.8401\n",
      "Epoch 24/30\n",
      "254/254 - 1s - loss: 0.2541 - root_mean_squared_error: 0.5041 - val_loss: 0.6184 - val_root_mean_squared_error: 0.7864\n",
      "Epoch 25/30\n",
      "254/254 - 1s - loss: 0.2481 - root_mean_squared_error: 0.4981 - val_loss: 0.6564 - val_root_mean_squared_error: 0.8102\n",
      "Epoch 26/30\n",
      "254/254 - 1s - loss: 0.2414 - root_mean_squared_error: 0.4913 - val_loss: 0.6525 - val_root_mean_squared_error: 0.8078\n",
      "Epoch 27/30\n",
      "254/254 - 1s - loss: 0.2390 - root_mean_squared_error: 0.4888 - val_loss: 0.7495 - val_root_mean_squared_error: 0.8657\n",
      "Epoch 28/30\n",
      "254/254 - 1s - loss: 0.2354 - root_mean_squared_error: 0.4852 - val_loss: 0.6434 - val_root_mean_squared_error: 0.8021\n",
      "Epoch 29/30\n",
      "254/254 - 1s - loss: 0.2252 - root_mean_squared_error: 0.4746 - val_loss: 0.6421 - val_root_mean_squared_error: 0.8013\n",
      "Epoch 30/30\n",
      "254/254 - 1s - loss: 0.2191 - root_mean_squared_error: 0.4681 - val_loss: 0.6219 - val_root_mean_squared_error: 0.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168a5da7790>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_cs = train_embed_cs_en.shape[1]\n",
    "\n",
    "# define network\n",
    "model_cs = Sequential()\n",
    "model_cs.add(Dense(64, input_shape=(n_words_cs,), activation='relu'))\n",
    "model_cs.add(Dense(64, activation='relu'))\n",
    "model_cs.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_cs.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_cs.fit(train_embed_cs_en, train_cs['z-score'], epochs=30, verbose=2,validation_data=(dev_embed_cs_en, dev_cs['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.788632\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, rmse = model_cs.evaluate(dev_embed_cs_en, dev_cs['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cs['DL_embed'] = model_cs.predict(train_embed_cs_en)\n",
    "dev_cs['DL_embed'] = model_cs.predict(dev_embed_cs_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> ru-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "394/394 - 2s - loss: 0.7443 - root_mean_squared_error: 0.8627 - val_loss: 0.8555 - val_root_mean_squared_error: 0.9249\n",
      "Epoch 2/30\n",
      "394/394 - 1s - loss: 0.7051 - root_mean_squared_error: 0.8397 - val_loss: 0.8023 - val_root_mean_squared_error: 0.8957\n",
      "Epoch 3/30\n",
      "394/394 - 1s - loss: 0.6750 - root_mean_squared_error: 0.8216 - val_loss: 0.7534 - val_root_mean_squared_error: 0.8680\n",
      "Epoch 4/30\n",
      "394/394 - 1s - loss: 0.6536 - root_mean_squared_error: 0.8085 - val_loss: 0.7562 - val_root_mean_squared_error: 0.8696\n",
      "Epoch 5/30\n",
      "394/394 - 1s - loss: 0.6304 - root_mean_squared_error: 0.7940 - val_loss: 0.7986 - val_root_mean_squared_error: 0.8936\n",
      "Epoch 6/30\n",
      "394/394 - 1s - loss: 0.6173 - root_mean_squared_error: 0.7857 - val_loss: 0.7604 - val_root_mean_squared_error: 0.8720\n",
      "Epoch 7/30\n",
      "394/394 - 1s - loss: 0.5996 - root_mean_squared_error: 0.7743 - val_loss: 0.8123 - val_root_mean_squared_error: 0.9013\n",
      "Epoch 8/30\n",
      "394/394 - 1s - loss: 0.5859 - root_mean_squared_error: 0.7655 - val_loss: 0.7560 - val_root_mean_squared_error: 0.8695\n",
      "Epoch 9/30\n",
      "394/394 - 1s - loss: 0.5739 - root_mean_squared_error: 0.7576 - val_loss: 0.8325 - val_root_mean_squared_error: 0.9124\n",
      "Epoch 10/30\n",
      "394/394 - 1s - loss: 0.5631 - root_mean_squared_error: 0.7504 - val_loss: 0.7519 - val_root_mean_squared_error: 0.8671\n",
      "Epoch 11/30\n",
      "394/394 - 1s - loss: 0.5491 - root_mean_squared_error: 0.7410 - val_loss: 0.9823 - val_root_mean_squared_error: 0.9911\n",
      "Epoch 12/30\n",
      "394/394 - 1s - loss: 0.5414 - root_mean_squared_error: 0.7358 - val_loss: 0.8250 - val_root_mean_squared_error: 0.9083\n",
      "Epoch 13/30\n",
      "394/394 - 1s - loss: 0.5295 - root_mean_squared_error: 0.7277 - val_loss: 0.8371 - val_root_mean_squared_error: 0.9149\n",
      "Epoch 14/30\n",
      "394/394 - 1s - loss: 0.5172 - root_mean_squared_error: 0.7192 - val_loss: 0.8493 - val_root_mean_squared_error: 0.9216\n",
      "Epoch 15/30\n",
      "394/394 - 1s - loss: 0.5120 - root_mean_squared_error: 0.7155 - val_loss: 0.8431 - val_root_mean_squared_error: 0.9182\n",
      "Epoch 16/30\n",
      "394/394 - 1s - loss: 0.5020 - root_mean_squared_error: 0.7085 - val_loss: 0.8645 - val_root_mean_squared_error: 0.9298\n",
      "Epoch 17/30\n",
      "394/394 - 1s - loss: 0.4945 - root_mean_squared_error: 0.7032 - val_loss: 1.1203 - val_root_mean_squared_error: 1.0585\n",
      "Epoch 18/30\n",
      "394/394 - 1s - loss: 0.4849 - root_mean_squared_error: 0.6963 - val_loss: 0.7701 - val_root_mean_squared_error: 0.8776\n",
      "Epoch 19/30\n",
      "394/394 - 1s - loss: 0.4803 - root_mean_squared_error: 0.6931 - val_loss: 0.8262 - val_root_mean_squared_error: 0.9090\n",
      "Epoch 20/30\n",
      "394/394 - 1s - loss: 0.4732 - root_mean_squared_error: 0.6879 - val_loss: 0.9174 - val_root_mean_squared_error: 0.9578\n",
      "Epoch 21/30\n",
      "394/394 - 1s - loss: 0.4609 - root_mean_squared_error: 0.6789 - val_loss: 0.9608 - val_root_mean_squared_error: 0.9802\n",
      "Epoch 22/30\n",
      "394/394 - 1s - loss: 0.4584 - root_mean_squared_error: 0.6771 - val_loss: 0.8462 - val_root_mean_squared_error: 0.9199\n",
      "Epoch 23/30\n",
      "394/394 - 1s - loss: 0.4494 - root_mean_squared_error: 0.6704 - val_loss: 0.8097 - val_root_mean_squared_error: 0.8998\n",
      "Epoch 24/30\n",
      "394/394 - 1s - loss: 0.4449 - root_mean_squared_error: 0.6670 - val_loss: 0.7935 - val_root_mean_squared_error: 0.8908\n",
      "Epoch 25/30\n",
      "394/394 - 1s - loss: 0.4365 - root_mean_squared_error: 0.6607 - val_loss: 0.8568 - val_root_mean_squared_error: 0.9256\n",
      "Epoch 26/30\n",
      "394/394 - 1s - loss: 0.4300 - root_mean_squared_error: 0.6557 - val_loss: 0.8775 - val_root_mean_squared_error: 0.9367\n",
      "Epoch 27/30\n",
      "394/394 - 1s - loss: 0.4218 - root_mean_squared_error: 0.6494 - val_loss: 0.9122 - val_root_mean_squared_error: 0.9551\n",
      "Epoch 28/30\n",
      "394/394 - 1s - loss: 0.4161 - root_mean_squared_error: 0.6451 - val_loss: 0.8236 - val_root_mean_squared_error: 0.9075\n",
      "Epoch 29/30\n",
      "394/394 - 1s - loss: 0.4130 - root_mean_squared_error: 0.6427 - val_loss: 0.8778 - val_root_mean_squared_error: 0.9369\n",
      "Epoch 30/30\n",
      "394/394 - 1s - loss: 0.4031 - root_mean_squared_error: 0.6349 - val_loss: 0.8588 - val_root_mean_squared_error: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168a55a4850>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_ru = train_embed_ru_en.shape[1]\n",
    "\n",
    "# define network\n",
    "model_ru = Sequential()\n",
    "model_ru.add(Dense(64, input_shape=(n_words_ru,), activation='relu'))\n",
    "model_ru.add(Dense(64, activation='relu'))\n",
    "model_ru.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_ru.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_ru.fit(train_embed_ru_en, train_ru['z-score'], epochs=30, verbose=2,validation_data=(dev_embed_ru_en, dev_ru['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.926702\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, rmse = model_ru.evaluate(dev_embed_ru_en, dev_ru['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ru['DL_embed'] = model_ru.predict(train_embed_ru_en)\n",
    "dev_ru['DL_embed'] = model_ru.predict(dev_embed_ru_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> zh-en <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "578/578 - 2s - loss: 0.7215 - root_mean_squared_error: 0.8494 - val_loss: 0.7226 - val_root_mean_squared_error: 0.8500\n",
      "Epoch 2/30\n",
      "578/578 - 2s - loss: 0.6755 - root_mean_squared_error: 0.8219 - val_loss: 0.7094 - val_root_mean_squared_error: 0.8423\n",
      "Epoch 3/30\n",
      "578/578 - 2s - loss: 0.6481 - root_mean_squared_error: 0.8051 - val_loss: 0.7482 - val_root_mean_squared_error: 0.8650\n",
      "Epoch 4/30\n",
      "578/578 - 2s - loss: 0.6316 - root_mean_squared_error: 0.7947 - val_loss: 0.6990 - val_root_mean_squared_error: 0.8361\n",
      "Epoch 5/30\n",
      "578/578 - 3s - loss: 0.6148 - root_mean_squared_error: 0.7841 - val_loss: 0.7313 - val_root_mean_squared_error: 0.8552\n",
      "Epoch 6/30\n",
      "578/578 - 2s - loss: 0.6010 - root_mean_squared_error: 0.7752 - val_loss: 0.6884 - val_root_mean_squared_error: 0.8297\n",
      "Epoch 7/30\n",
      "578/578 - 2s - loss: 0.5879 - root_mean_squared_error: 0.7668 - val_loss: 0.6884 - val_root_mean_squared_error: 0.8297\n",
      "Epoch 8/30\n",
      "578/578 - 2s - loss: 0.5762 - root_mean_squared_error: 0.7591 - val_loss: 0.6789 - val_root_mean_squared_error: 0.8239\n",
      "Epoch 9/30\n",
      "578/578 - 2s - loss: 0.5686 - root_mean_squared_error: 0.7541 - val_loss: 0.7062 - val_root_mean_squared_error: 0.8404\n",
      "Epoch 10/30\n",
      "578/578 - 2s - loss: 0.5571 - root_mean_squared_error: 0.7464 - val_loss: 0.7277 - val_root_mean_squared_error: 0.8531\n",
      "Epoch 11/30\n",
      "578/578 - 2s - loss: 0.5485 - root_mean_squared_error: 0.7406 - val_loss: 0.7291 - val_root_mean_squared_error: 0.8539\n",
      "Epoch 12/30\n",
      "578/578 - 2s - loss: 0.5430 - root_mean_squared_error: 0.7369 - val_loss: 0.6805 - val_root_mean_squared_error: 0.8249\n",
      "Epoch 13/30\n",
      "578/578 - 2s - loss: 0.5341 - root_mean_squared_error: 0.7308 - val_loss: 0.6713 - val_root_mean_squared_error: 0.8194\n",
      "Epoch 14/30\n",
      "578/578 - 2s - loss: 0.5286 - root_mean_squared_error: 0.7270 - val_loss: 0.7666 - val_root_mean_squared_error: 0.8756\n",
      "Epoch 15/30\n",
      "578/578 - 2s - loss: 0.5212 - root_mean_squared_error: 0.7220 - val_loss: 0.6785 - val_root_mean_squared_error: 0.8237\n",
      "Epoch 16/30\n",
      "578/578 - 2s - loss: 0.5163 - root_mean_squared_error: 0.7186 - val_loss: 0.7905 - val_root_mean_squared_error: 0.8891\n",
      "Epoch 17/30\n",
      "578/578 - 2s - loss: 0.5066 - root_mean_squared_error: 0.7118 - val_loss: 0.7189 - val_root_mean_squared_error: 0.8479\n",
      "Epoch 18/30\n",
      "578/578 - 2s - loss: 0.5024 - root_mean_squared_error: 0.7088 - val_loss: 0.6938 - val_root_mean_squared_error: 0.8330\n",
      "Epoch 19/30\n",
      "578/578 - 2s - loss: 0.4960 - root_mean_squared_error: 0.7043 - val_loss: 0.7003 - val_root_mean_squared_error: 0.8369\n",
      "Epoch 20/30\n",
      "578/578 - 2s - loss: 0.4897 - root_mean_squared_error: 0.6998 - val_loss: 0.7068 - val_root_mean_squared_error: 0.8407\n",
      "Epoch 21/30\n",
      "578/578 - 2s - loss: 0.4831 - root_mean_squared_error: 0.6950 - val_loss: 0.6966 - val_root_mean_squared_error: 0.8346\n",
      "Epoch 22/30\n",
      "578/578 - 2s - loss: 0.4755 - root_mean_squared_error: 0.6896 - val_loss: 0.7244 - val_root_mean_squared_error: 0.8511\n",
      "Epoch 23/30\n",
      "578/578 - 2s - loss: 0.4677 - root_mean_squared_error: 0.6839 - val_loss: 0.7054 - val_root_mean_squared_error: 0.8399\n",
      "Epoch 24/30\n",
      "578/578 - 2s - loss: 0.4624 - root_mean_squared_error: 0.6800 - val_loss: 0.7679 - val_root_mean_squared_error: 0.8763\n",
      "Epoch 25/30\n",
      "578/578 - 2s - loss: 0.4545 - root_mean_squared_error: 0.6742 - val_loss: 0.7311 - val_root_mean_squared_error: 0.8550\n",
      "Epoch 26/30\n",
      "578/578 - 2s - loss: 0.4455 - root_mean_squared_error: 0.6674 - val_loss: 0.7193 - val_root_mean_squared_error: 0.8481\n",
      "Epoch 27/30\n",
      "578/578 - 2s - loss: 0.4393 - root_mean_squared_error: 0.6628 - val_loss: 0.7246 - val_root_mean_squared_error: 0.8512\n",
      "Epoch 28/30\n",
      "578/578 - 2s - loss: 0.4360 - root_mean_squared_error: 0.6603 - val_loss: 0.7759 - val_root_mean_squared_error: 0.8808\n",
      "Epoch 29/30\n",
      "578/578 - 2s - loss: 0.4258 - root_mean_squared_error: 0.6525 - val_loss: 0.8042 - val_root_mean_squared_error: 0.8967\n",
      "Epoch 30/30\n",
      "578/578 - 2s - loss: 0.4169 - root_mean_squared_error: 0.6457 - val_loss: 0.7934 - val_root_mean_squared_error: 0.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168fa8fa940>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_zh_en = train_embed_zh_en.shape[1]\n",
    "\n",
    "# define network\n",
    "model_zhen = Sequential()\n",
    "model_zhen.add(Dense(64, input_shape=(n_words_zh_en,), activation='relu'))\n",
    "model_zhen.add(Dense(64, activation='relu'))\n",
    "model_zhen.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_zhen.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_zhen.fit(train_embed_zh_en, train_zhen['z-score'], epochs=30, verbose=2,validation_data=(dev_embed_zh_en, dev_zhen['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.890740\n"
     ]
    }
   ],
   "source": [
    "# # evaluate\n",
    "loss, rmse = model_zhen.evaluate(dev_embed_zh_en, dev_zhen['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zhen['DL_embed'] = model_zhen.predict(train_embed_zh_en)\n",
    "dev_zhen['DL_embed'] = model_zhen.predict(dev_embed_zh_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "148/148 - 4s - loss: 0.7996 - root_mean_squared_error: 0.8942 - val_loss: 0.6469 - val_root_mean_squared_error: 0.8043\n",
      "Epoch 2/30\n",
      "148/148 - 1s - loss: 0.6990 - root_mean_squared_error: 0.8361 - val_loss: 0.5757 - val_root_mean_squared_error: 0.7587\n",
      "Epoch 3/30\n",
      "148/148 - 1s - loss: 0.6262 - root_mean_squared_error: 0.7913 - val_loss: 0.7170 - val_root_mean_squared_error: 0.8467\n",
      "Epoch 4/30\n",
      "148/148 - 1s - loss: 0.5923 - root_mean_squared_error: 0.7696 - val_loss: 0.5675 - val_root_mean_squared_error: 0.7533\n",
      "Epoch 5/30\n",
      "148/148 - 1s - loss: 0.5586 - root_mean_squared_error: 0.7474 - val_loss: 0.5717 - val_root_mean_squared_error: 0.7561\n",
      "Epoch 6/30\n",
      "148/148 - 1s - loss: 0.5398 - root_mean_squared_error: 0.7347 - val_loss: 0.5759 - val_root_mean_squared_error: 0.7589\n",
      "Epoch 7/30\n",
      "148/148 - 1s - loss: 0.5174 - root_mean_squared_error: 0.7193 - val_loss: 0.5619 - val_root_mean_squared_error: 0.7496\n",
      "Epoch 8/30\n",
      "148/148 - 1s - loss: 0.4907 - root_mean_squared_error: 0.7005 - val_loss: 0.5610 - val_root_mean_squared_error: 0.7490\n",
      "Epoch 9/30\n",
      "148/148 - 1s - loss: 0.4682 - root_mean_squared_error: 0.6842 - val_loss: 0.5653 - val_root_mean_squared_error: 0.7519\n",
      "Epoch 10/30\n",
      "148/148 - 1s - loss: 0.4451 - root_mean_squared_error: 0.6672 - val_loss: 0.5788 - val_root_mean_squared_error: 0.7608\n",
      "Epoch 11/30\n",
      "148/148 - 1s - loss: 0.4322 - root_mean_squared_error: 0.6574 - val_loss: 0.6169 - val_root_mean_squared_error: 0.7855\n",
      "Epoch 12/30\n",
      "148/148 - 1s - loss: 0.4084 - root_mean_squared_error: 0.6391 - val_loss: 0.5651 - val_root_mean_squared_error: 0.7517\n",
      "Epoch 13/30\n",
      "148/148 - 1s - loss: 0.3941 - root_mean_squared_error: 0.6278 - val_loss: 0.5564 - val_root_mean_squared_error: 0.7459\n",
      "Epoch 14/30\n",
      "148/148 - 1s - loss: 0.3757 - root_mean_squared_error: 0.6129 - val_loss: 0.6113 - val_root_mean_squared_error: 0.7819\n",
      "Epoch 15/30\n",
      "148/148 - 1s - loss: 0.3542 - root_mean_squared_error: 0.5951 - val_loss: 0.6010 - val_root_mean_squared_error: 0.7753\n",
      "Epoch 16/30\n",
      "148/148 - 1s - loss: 0.3470 - root_mean_squared_error: 0.5890 - val_loss: 0.5737 - val_root_mean_squared_error: 0.7574\n",
      "Epoch 17/30\n",
      "148/148 - 1s - loss: 0.3304 - root_mean_squared_error: 0.5748 - val_loss: 0.6878 - val_root_mean_squared_error: 0.8293\n",
      "Epoch 18/30\n",
      "148/148 - 1s - loss: 0.3186 - root_mean_squared_error: 0.5644 - val_loss: 0.5520 - val_root_mean_squared_error: 0.7429\n",
      "Epoch 19/30\n",
      "148/148 - 1s - loss: 0.3055 - root_mean_squared_error: 0.5527 - val_loss: 0.5625 - val_root_mean_squared_error: 0.7500\n",
      "Epoch 20/30\n",
      "148/148 - 1s - loss: 0.2962 - root_mean_squared_error: 0.5442 - val_loss: 0.6678 - val_root_mean_squared_error: 0.8172\n",
      "Epoch 21/30\n",
      "148/148 - 1s - loss: 0.2893 - root_mean_squared_error: 0.5379 - val_loss: 0.6396 - val_root_mean_squared_error: 0.7997\n",
      "Epoch 22/30\n",
      "148/148 - 1s - loss: 0.2745 - root_mean_squared_error: 0.5240 - val_loss: 0.6757 - val_root_mean_squared_error: 0.8220\n",
      "Epoch 23/30\n",
      "148/148 - 1s - loss: 0.2650 - root_mean_squared_error: 0.5147 - val_loss: 0.6306 - val_root_mean_squared_error: 0.7941\n",
      "Epoch 24/30\n",
      "148/148 - 1s - loss: 0.2527 - root_mean_squared_error: 0.5027 - val_loss: 0.6227 - val_root_mean_squared_error: 0.7891\n",
      "Epoch 25/30\n",
      "148/148 - 1s - loss: 0.2414 - root_mean_squared_error: 0.4913 - val_loss: 0.6287 - val_root_mean_squared_error: 0.7929\n",
      "Epoch 26/30\n",
      "148/148 - 1s - loss: 0.2351 - root_mean_squared_error: 0.4849 - val_loss: 0.6815 - val_root_mean_squared_error: 0.8256\n",
      "Epoch 27/30\n",
      "148/148 - 1s - loss: 0.2284 - root_mean_squared_error: 0.4779 - val_loss: 0.5854 - val_root_mean_squared_error: 0.7651\n",
      "Epoch 28/30\n",
      "148/148 - 1s - loss: 0.2195 - root_mean_squared_error: 0.4685 - val_loss: 0.7627 - val_root_mean_squared_error: 0.8733\n",
      "Epoch 29/30\n",
      "148/148 - 1s - loss: 0.2097 - root_mean_squared_error: 0.4579 - val_loss: 0.6904 - val_root_mean_squared_error: 0.8309\n",
      "Epoch 30/30\n",
      "148/148 - 1s - loss: 0.2102 - root_mean_squared_error: 0.4584 - val_loss: 0.6286 - val_root_mean_squared_error: 0.7929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168fc6f1430>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_fi = train_embed_en_fi.shape[1]\n",
    "\n",
    "# define network\n",
    "model_fi = Sequential()\n",
    "model_fi.add(Dense(64, input_shape=(n_words_fi,), activation='relu'))\n",
    "model_fi.add(Dense(64, activation='relu'))\n",
    "model_fi.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_fi.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_fi.fit(train_embed_en_fi, train_fi['z-score'], epochs=30, verbose=2,validation_data=(dev_embed_en_fi, dev_fi['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.792861\n"
     ]
    }
   ],
   "source": [
    "# # evaluate\n",
    "loss, rmse = model_fi.evaluate(dev_embed_en_fi, dev_fi['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fi['DL_embed'] = model_fi.predict(train_embed_en_fi)\n",
    "dev_fi['DL_embed'] = model_fi.predict(dev_embed_en_fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-zh <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "224/224 - 2s - loss: 0.8283 - root_mean_squared_error: 0.9101 - val_loss: 0.7256 - val_root_mean_squared_error: 0.8518\n",
      "Epoch 2/30\n",
      "224/224 - 1s - loss: 0.7667 - root_mean_squared_error: 0.8756 - val_loss: 0.7904 - val_root_mean_squared_error: 0.8891\n",
      "Epoch 3/30\n",
      "224/224 - 1s - loss: 0.7294 - root_mean_squared_error: 0.8541 - val_loss: 1.1653 - val_root_mean_squared_error: 1.0795\n",
      "Epoch 4/30\n",
      "224/224 - 1s - loss: 0.6941 - root_mean_squared_error: 0.8331 - val_loss: 0.7039 - val_root_mean_squared_error: 0.8390\n",
      "Epoch 5/30\n",
      "224/224 - 1s - loss: 0.6640 - root_mean_squared_error: 0.8149 - val_loss: 0.6488 - val_root_mean_squared_error: 0.8055\n",
      "Epoch 6/30\n",
      "224/224 - 1s - loss: 0.6469 - root_mean_squared_error: 0.8043 - val_loss: 0.9750 - val_root_mean_squared_error: 0.9874\n",
      "Epoch 7/30\n",
      "224/224 - 1s - loss: 0.6304 - root_mean_squared_error: 0.7940 - val_loss: 0.8822 - val_root_mean_squared_error: 0.9393\n",
      "Epoch 8/30\n",
      "224/224 - 1s - loss: 0.6123 - root_mean_squared_error: 0.7825 - val_loss: 0.6727 - val_root_mean_squared_error: 0.8202\n",
      "Epoch 9/30\n",
      "224/224 - 1s - loss: 0.5957 - root_mean_squared_error: 0.7718 - val_loss: 0.8803 - val_root_mean_squared_error: 0.9382\n",
      "Epoch 10/30\n",
      "224/224 - 1s - loss: 0.5804 - root_mean_squared_error: 0.7619 - val_loss: 0.6487 - val_root_mean_squared_error: 0.8054\n",
      "Epoch 11/30\n",
      "224/224 - 1s - loss: 0.5643 - root_mean_squared_error: 0.7512 - val_loss: 0.8065 - val_root_mean_squared_error: 0.8981\n",
      "Epoch 12/30\n",
      "224/224 - 1s - loss: 0.5535 - root_mean_squared_error: 0.7440 - val_loss: 0.6322 - val_root_mean_squared_error: 0.7951\n",
      "Epoch 13/30\n",
      "224/224 - 1s - loss: 0.5424 - root_mean_squared_error: 0.7365 - val_loss: 0.6572 - val_root_mean_squared_error: 0.8107\n",
      "Epoch 14/30\n",
      "224/224 - 1s - loss: 0.5248 - root_mean_squared_error: 0.7244 - val_loss: 1.0541 - val_root_mean_squared_error: 1.0267\n",
      "Epoch 15/30\n",
      "224/224 - 1s - loss: 0.5223 - root_mean_squared_error: 0.7227 - val_loss: 0.6439 - val_root_mean_squared_error: 0.8024\n",
      "Epoch 16/30\n",
      "224/224 - 1s - loss: 0.5036 - root_mean_squared_error: 0.7097 - val_loss: 0.7488 - val_root_mean_squared_error: 0.8653\n",
      "Epoch 17/30\n",
      "224/224 - 1s - loss: 0.5000 - root_mean_squared_error: 0.7071 - val_loss: 0.7272 - val_root_mean_squared_error: 0.8527\n",
      "Epoch 18/30\n",
      "224/224 - 1s - loss: 0.4874 - root_mean_squared_error: 0.6981 - val_loss: 0.6490 - val_root_mean_squared_error: 0.8056\n",
      "Epoch 19/30\n",
      "224/224 - 1s - loss: 0.4860 - root_mean_squared_error: 0.6971 - val_loss: 0.7413 - val_root_mean_squared_error: 0.8610\n",
      "Epoch 20/30\n",
      "224/224 - 1s - loss: 0.4685 - root_mean_squared_error: 0.6845 - val_loss: 0.6515 - val_root_mean_squared_error: 0.8071\n",
      "Epoch 21/30\n",
      "224/224 - 1s - loss: 0.4612 - root_mean_squared_error: 0.6791 - val_loss: 0.6514 - val_root_mean_squared_error: 0.8071\n",
      "Epoch 22/30\n",
      "224/224 - 1s - loss: 0.4573 - root_mean_squared_error: 0.6763 - val_loss: 0.6829 - val_root_mean_squared_error: 0.8264\n",
      "Epoch 23/30\n",
      "224/224 - 1s - loss: 0.4479 - root_mean_squared_error: 0.6693 - val_loss: 0.8343 - val_root_mean_squared_error: 0.9134\n",
      "Epoch 24/30\n",
      "224/224 - 1s - loss: 0.4333 - root_mean_squared_error: 0.6582 - val_loss: 0.8372 - val_root_mean_squared_error: 0.9150\n",
      "Epoch 25/30\n",
      "224/224 - 1s - loss: 0.4265 - root_mean_squared_error: 0.6530 - val_loss: 0.7363 - val_root_mean_squared_error: 0.8581\n",
      "Epoch 26/30\n",
      "224/224 - 1s - loss: 0.4186 - root_mean_squared_error: 0.6470 - val_loss: 0.7306 - val_root_mean_squared_error: 0.8548\n",
      "Epoch 27/30\n",
      "224/224 - 1s - loss: 0.4095 - root_mean_squared_error: 0.6399 - val_loss: 0.7027 - val_root_mean_squared_error: 0.8383\n",
      "Epoch 28/30\n",
      "224/224 - 1s - loss: 0.4014 - root_mean_squared_error: 0.6336 - val_loss: 0.6960 - val_root_mean_squared_error: 0.8342\n",
      "Epoch 29/30\n",
      "224/224 - 1s - loss: 0.3950 - root_mean_squared_error: 0.6285 - val_loss: 0.8137 - val_root_mean_squared_error: 0.9021\n",
      "Epoch 30/30\n",
      "224/224 - 1s - loss: 0.3922 - root_mean_squared_error: 0.6262 - val_loss: 0.6628 - val_root_mean_squared_error: 0.8141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168a5508040>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_en_zh = train_embed_en_zh.shape[1]\n",
    "\n",
    "# define network\n",
    "model_enzh = Sequential()\n",
    "model_enzh.add(Dense(64, input_shape=(n_words_en_zh,), activation='relu'))\n",
    "model_enzh.add(Dense(64, activation='relu'))\n",
    "model_enzh.add(Dense(1))\n",
    "\n",
    "# compile network\n",
    "model_enzh.compile(optimizer='rmsprop',loss='mse',metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# fit network\n",
    "model_enzh.fit(train_embed_en_zh, train_enzh['z-score'], epochs=30, verbose=2,validation_data=(dev_embed_en_zh, dev_enzh['z-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev RMSE: 0.835161\n"
     ]
    }
   ],
   "source": [
    "# # evaluate\n",
    "loss, rmse = model_enzh.evaluate(dev_embed_en_zh, dev_enzh['z-score'], verbose=0)\n",
    "print('Dev RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enzh['DL_embed'] = model_enzh.predict(train_embed_en_zh)\n",
    "dev_enzh['DL_embed'] = model_enzh.predict(dev_embed_en_zh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 7. Combining metrics</font> <a class=\"anchor\" id=\"comb\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns so they fit and match each other to then be concatenated\n",
    "en_zh.rename(columns={'bleu':'bleu_1','chrf':'chrf_1', 'meteor':'meteor_1','ter':'ter_1','gleu':'gleu_1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all corpora in a single one\n",
    "DF_all = pd.concat([cs_en, ru_en, zh_en, de_en, en_fi, en_zh])\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the concatenated corpus into train and development set\n",
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66255, 28396)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining that the X variables are for the metrics that performed better (BLEU, CHRF, GLEU, METEOR, TER)\n",
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "\n",
    "# Defining the target as the z-score\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bleu_1      0\n",
       "chrf_1      0\n",
       "gleu_1      0\n",
       "meteor_1    0\n",
       "ter_1       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and the target for development set\n",
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.795940796301352 \n",
      "Dev: 0.8112477311786886\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with other combinations (all corpora seperately and also for all English translations together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all corpora with English translation\n",
    "DF_all = pd.concat([cs_en, ru_en, zh_en, de_en])\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54377, 23305)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8022200327555328 \n",
      "Dev: 0.7967414039498808\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all = en_fi\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4723, 2025)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6508263053284159 \n",
      "Dev: 0.7010606121887464\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all = en_zh\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7154, 3067)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7836489202961927 \n",
      "Dev: 0.8077886102885207\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Czech-en translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all = cs_en\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8109, 3476)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7232785380643042 \n",
      "Dev: 0.7850163510714665\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Russian- en translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all = ru_en\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12583, 5394)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7852682175642716 \n",
      "Dev: 0.8363676830425896\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese- en translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all = zh_en\n",
    "DF_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(DF_all, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18491, 7925)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_train = train['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[['bleu_1','chrf_1','gleu_1', 'meteor_1', 'ter_1']]\n",
    "y_dev = dev['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGB = GradientBoostingRegressor(random_state=42)\n",
    "modelGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = modelGB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7956424407116267 \n",
      "Dev: 0.8094406698213367\n"
     ]
    }
   ],
   "source": [
    "pred_dev = modelGB.predict(X_dev)\n",
    "print('Train:',mean_squared_error(y_train, pred_train, squared=False),'\\nDev:',mean_squared_error(y_dev, pred_dev, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['grad_boost'] = pred_train\n",
    "dev['grad_boost'] = pred_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 8. Correlations (Pearson's and Kendall's Tau)</font> <a class=\"anchor\" id=\"corr\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_corr1=[]\n",
    "for col in ['euclidean_dists_1','manhattan_dists_1','cosine_sim_1', 'jaccard_sim_1','bleu_1','rouge-1_1','rouge-l_1','chrf_1','ter_1', 'meteor_1','gleu_1']:\n",
    "    for i in [cs_en, ru_en, zh_en, de_en, en_fi]:\n",
    "        metric_corr1.append(round(pearsonr(i['z-score'], i[col])[0], 3))\n",
    "        metric_corr1.append(round(kendalltau(i['z-score'], i[col])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_corr2=[]\n",
    "for col in ['euclidean_dists_2','manhattan_dists_2','cosine_sim_2', 'jaccard_sim_2','bleu_2','rouge-1_2','rouge-l_2','chrf_2','ter_2', 'meteor_2','gleu_2']:\n",
    "    for i in [cs_en, ru_en, zh_en, de_en, en_fi]:\n",
    "        metric_corr2.append(round(pearsonr(i['z-score'], i[col])[0], 3))\n",
    "        metric_corr2.append(round(kendalltau(i['z-score'], i[col])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_zh_P=[]\n",
    "en_zh_K = []\n",
    "for col in ['euclidean_dists','manhattan_dists','cosine_sim', 'jaccard_sim','bleu','rouge-1','rouge-l','chrf','ter', 'meteor','gleu']:\n",
    "    en_zh_P.append(round(pearsonr(en_zh['z-score'], en_zh[col])[0], 3))\n",
    "    en_zh_K.append(round(kendalltau(en_zh['z-score'], en_zh[col])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=['euclidean_dists','manhattan_dists','cosine_sim', 'jaccard_sim','bleu','rouge-1','rouge-l','chrf','ter', 'meteor','gleu']\n",
    "cols=['cs_en_P','cs_en_K','ru_en_P','ru_en_K','zh_en_P','zh_en_K','de_en_P','de_en_K','en_fi_P','en_fi_K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreProc1 = pd.DataFrame(np.array(metric_corr1).reshape((11,10)), index=metrics, columns=cols)\n",
    "PreProc2 = pd.DataFrame(np.array(metric_corr2).reshape((11,10)), index=metrics, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreProc1['en_zh_P'] = en_zh_P\n",
    "PreProc1['en_zh_K'] = en_zh_K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to an Excel file the tables with the Pearson and Kendall's Tau correlation scores, for Preprocessing 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreProc1.to_excel('correlations_proc1.xls')\n",
    "# PreProc2.to_excel('correlations_proc2.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### For Neural Networks with bag of words:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874 0.266\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['NN_bow'])[0], 3), round(pearsonr(dev['z-score'], dev['NN_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664 0.187\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['NN_bow'])[0], 3),round(kendalltau(dev['z-score'], dev['NN_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979 0.342\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_fi['z-score'], train_fi['NN_bow'])[0], 3), round(pearsonr(dev_fi['z-score'], dev_fi['NN_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907 0.221\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_fi['z-score'], train_fi['NN_bow'])[0], 3),round(kendalltau(dev_fi['z-score'], dev_fi['NN_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72 0.34\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_zh['z-score'], train_zh['NN_bow'])[0], 3), round(pearsonr(dev_zh['z-score'], dev_zh['NN_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.518 0.224\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_zh['z-score'], train_zh['NN_bow'])[0], 3),round(kendalltau(dev_zh['z-score'], dev_zh['NN_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### For Deep Learning with bag of words:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882 0.287\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['DL_bow'])[0], 3), round(pearsonr(dev['z-score'], dev['DL_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71 0.202\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['DL_bow'])[0], 3),round(kendalltau(dev['z-score'], dev['DL_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969 0.385\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_fi['z-score'], train_fi['DL_bow'])[0], 3), round(pearsonr(dev_fi['z-score'], dev_fi['DL_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872 0.244\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_fi['z-score'], train_fi['DL_bow'])[0], 3),round(kendalltau(dev_fi['z-score'], dev_fi['DL_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.673 0.353\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_zh['z-score'], train_zh['DL_bow'])[0], 3), round(pearsonr(dev_zh['z-score'], dev_zh['DL_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496 0.233\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_zh['z-score'], train_zh['DL_bow'])[0], 3),round(kendalltau(dev_zh['z-score'], dev_zh['DL_bow'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### For Neural Networks with word embeddings:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951 0.31\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['NN_embedded'])[0], 3), round(pearsonr(dev['z-score'], dev['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788 0.22\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['NN_embedded'])[0], 3),round(kendalltau(dev['z-score'], dev['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> cs-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776 0.484\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_cs['z-score'], train_cs['NN_embedded'])[0], 3), round(pearsonr(dev_cs['z-score'], dev_cs['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548 0.321\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_cs['z-score'], train_cs['NN_embedded'])[0], 3),round(kendalltau(dev_cs['z-score'], dev_cs['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> ru-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653 0.274\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_ru['z-score'], train_ru['NN_embedded'])[0], 3), round(pearsonr(dev_ru['z-score'], dev_ru['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.436 0.193\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_ru['z-score'], train_ru['NN_embedded'])[0], 3),round(kendalltau(dev_ru['z-score'], dev_ru['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> zh-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606 0.35\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_zhen['z-score'], train_zhen['NN_embedded'])[0], 3), round(pearsonr(dev_zhen['z-score'], dev_zhen['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.418 0.239\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_zhen['z-score'], train_zhen['NN_embedded'])[0], 3),round(kendalltau(dev_zhen['z-score'], dev_zhen['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785 0.392\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_fi['z-score'], train_fi['NN_embedded'])[0], 3), round(pearsonr(dev_fi['z-score'], dev_fi['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585 0.266\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_fi['z-score'], train_fi['NN_embedded'])[0], 3),round(kendalltau(dev_fi['z-score'], dev_fi['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.439\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_enzh['z-score'], train_enzh['NN_embedded'])[0], 3), round(pearsonr(dev_enzh['z-score'], dev_enzh['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498 0.285\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_enzh['z-score'], train_enzh['NN_embedded'])[0], 3),round(kendalltau(dev_enzh['z-score'], dev_enzh['NN_embedded'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### For Deep Learning with word embeddings:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> cs-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878 0.509\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_cs['z-score'], train_cs['DL_embed'])[0], 3), round(pearsonr(dev_cs['z-score'], dev_cs['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667 0.348\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_cs['z-score'], train_cs['DL_embed'])[0], 3),round(kendalltau(dev_cs['z-score'], dev_cs['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> ru-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653 0.274\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_ru['z-score'], train_ru['DL_embed'])[0], 3), round(pearsonr(dev_ru['z-score'], dev_ru['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.436 0.193\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_ru['z-score'], train_ru['DL_embed'])[0], 3),round(kendalltau(dev_ru['z-score'], dev_ru['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> zh-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693 0.34\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_zhen['z-score'], train_zhen['DL_embed'])[0], 3), round(pearsonr(dev_zhen['z-score'], dev_zhen['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481 0.236\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_zhen['z-score'], train_zhen['DL_embed'])[0], 3),round(kendalltau(dev_zhen['z-score'], dev_zhen['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704 0.342\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['DL_embed'])[0], 3), round(pearsonr(dev['z-score'], dev['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.474 0.238\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['DL_embed'])[0], 3),round(kendalltau(dev['z-score'], dev['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91 0.422\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_fi['z-score'], train_fi['DL_embed'])[0], 3), round(pearsonr(dev_fi['z-score'], dev_fi['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738 0.288\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_fi['z-score'], train_fi['DL_embed'])[0], 3),round(kendalltau(dev_fi['z-score'], dev_fi['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> en-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783 0.452\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train_enzh['z-score'], train_enzh['DL_embed'])[0], 3), round(pearsonr(dev_enzh['z-score'], dev_enzh['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576 0.298\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train_enzh['z-score'], train_enzh['DL_embed'])[0], 3),round(kendalltau(dev_enzh['z-score'], dev_enzh['DL_embed'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### For Ensemble with past metrics:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> English only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.397 0.388\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.261 0.263\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681 0.62\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.457 0.398\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.542 0.494\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362 0.331\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Czech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554 0.454\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362 0.314\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.448 0.359\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.283 0.249\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Chinese - eng translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.422 0.367\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268 0.241\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.419 0.404\n"
     ]
    }
   ],
   "source": [
    "# Pearson for training and development set\n",
    "print(round(pearsonr(train['z-score'], train['grad_boost'])[0], 3), round(pearsonr(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.277 0.273\n"
     ]
    }
   ],
   "source": [
    "# Kendall's Tau for training and development set\n",
    "print(round(kendalltau(train['z-score'], train['grad_boost'])[0], 3),round(kendalltau(dev['z-score'], dev['grad_boost'])[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 9. Applying it to test set</font> <a class=\"anchor\" id=\"test\"></a>\n",
    "\n",
    "  [Back to introduction](#title)\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the test corpora already with the the MT metrics used in the ensemble model -> retrieved from the TM Project - Test Set Preparation\n",
    "en_fi, cs_en, en_zh, ru_en, zh_en, de_en = pd.read_csv(\"en_fi_test.csv\"), pd.read_csv(\"cs_en_test.csv\"), pd.read_csv(\"en_zh_test.csv\"), pd.read_csv(\"ru_en_test.csv\"), pd.read_csv(\"zh_en_test.csv\"), pd.read_csv(\"de_en_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all corpora\n",
    "test_set = pd.concat([cs_en, ru_en, zh_en, de_en, en_fi, en_zh])\n",
    "test_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the X variables as the same metrics used in the training of the Ensemble model\n",
    "X_test = test_set[['bleu','chrf','gleu', 'meteor', 'ter_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = modelGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8097, 8732, 22128, 13157, 25352, 28404)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_fi), len(cs_en), len(en_zh), len(ru_en), len(zh_en), len(de_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['metric_scores'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "source               0\n",
       "reference            0\n",
       "translation          0\n",
       "clean_translation    0\n",
       "clean_reference      0\n",
       "bleu                 0\n",
       "ter_1                0\n",
       "chrf                 0\n",
       "meteor               0\n",
       "gleu                 0\n",
       "metric               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[(21889-13157):21889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the joined test set in separate sets to later join in each language-pair corpus\n",
    "\n",
    "cs_en_test = test_set[:8732]\n",
    "\n",
    "en_zh_test = test_set[-22128:]\n",
    "\n",
    "en_fi_test = test_set[(83742-8097):83742]\n",
    "\n",
    "de_en_test = test_set[(75645-28404):75645]\n",
    "\n",
    "zh_en_test = test_set[(47241-25352):47241]\n",
    "\n",
    "ru_en_test = test_set[(21889-13157):21889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the columns: Source, Reference, Translation and Metric Scores (the predictions of the z-score)\n",
    "\n",
    "cs_en_test = cs_en_test[['source','reference','translation','metric_scores']]\n",
    "ru_en_test = ru_en_test[['source','reference','translation','metric_scores']]\n",
    "zh_en_test = zh_en_test[['source','reference','translation','metric_scores']]\n",
    "de_en_test = de_en_test[['source','reference','translation','metric_scores']]\n",
    "en_fi_test = en_fi_test[['source','reference','translation','metric_scores']]\n",
    "en_zh_test = en_zh_test[['source','reference','translation','metric_scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the index to have a cleaner aspect\n",
    "\n",
    "cs_en_test.reset_index(inplace=True, drop=True)\n",
    "en_zh_test.reset_index(inplace=True, drop=True)\n",
    "zh_en_test.reset_index(inplace=True, drop=True)\n",
    "de_en_test.reset_index(inplace=True, drop=True)\n",
    "en_fi_test.reset_index(inplace=True, drop=True)\n",
    "ru_en_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the final corpora already with the predictions into the resulting csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_en_test.to_csv('corpus/testset/cs-en/scores.csv')\n",
    "en_zh_test.to_csv('corpus/testset/en-zh/scores.csv')\n",
    "zh_en_test.to_csv('corpus/testset/zh-en/scores.csv')\n",
    "de_en_test.to_csv('corpus/testset/de-en/scores.csv')\n",
    "en_fi_test.to_csv('corpus/testset/en-fi/scores.csv')\n",
    "ru_en_test.to_csv('corpus/testset/ru-en/scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
